{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\joaoc\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\joaoc\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\joaoc\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import ast\n",
    "from surprise import Dataset, Reader, KNNBasic\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.decomposition import LatentDirichletAllocation, TruncatedSVD\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from surprise.model_selection import train_test_split\n",
    "from sklearn.model_selection import train_test_split as skl_train_test_split\n",
    "from datetime import datetime\n",
    "from gensim.models.doc2vec import Doc2Vec,TaggedDocument\n",
    "\n",
    "\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data\n",
    "\n",
    "df_business = pd.read_csv('yelp_academic_dataset_business.csv')\n",
    "df_checkin = pd.read_csv('yelp_academic_dataset_checkin.csv')\n",
    "df_review=pd.read_csv('yelp_academic_dataset_review.csv')\n",
    "df_tip=pd.read_csv('yelp_academic_dataset_tip.csv')\n",
    "df_user=pd.read_csv('yelp_academic_dataset_user.csv')\n",
    "\n",
    "# print(df_business.columns)\n",
    "# print(df_checkin.columns)\n",
    "# print(df_review.columns)\n",
    "# print(df_tip.columns)\n",
    "# print(df_user.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Subset de dados\n",
    "\n",
    "df_business_filadelfia = df_business[(df_business['city'] == 'Philadelphia') & (df_business['categories'].str.contains('Restaurants', na=False)) & (df_business['is_open']==1)].reset_index(drop=True)\n",
    "df_business_filadelfia=df_business_filadelfia[['business_id', 'name', 'stars', 'review_count', 'attributes', 'categories', 'hours']].reset_index(drop=True)\n",
    "\n",
    "df_review_filadelfia = df_review[df_review['business_id'].isin(df_business_filadelfia['business_id'])]\n",
    "df_review_filadelfia=df_review_filadelfia[['review_id', 'user_id', 'business_id', 'stars', 'text', 'date']]\n",
    "df_review_filadelfia['liked'] = (df_review_filadelfia['stars'] > 3).astype(int)\n",
    "df_review_filadelfia_profiles = df_review_filadelfia[df_review_filadelfia['liked'] == 1].reset_index(drop=True)\n",
    "\n",
    "df_user_filadelfia = df_user[df_user['user_id'].isin(df_review_filadelfia['user_id'])]\n",
    "df_user_filadelfia=df_user_filadelfia[['user_id', 'name', 'review_count', 'yelping_since', 'elite', 'average_stars']].reset_index(drop=True)\n",
    "\n",
    "# Perfis LDA\n",
    "user_profile = pd.read_csv(\"user_profiles.csv\")\n",
    "user_profile = user_profile.drop(columns=['Unnamed: 0'])\n",
    "restaurant_profile = pd.read_csv(\"restaurant_profiles.csv\")\n",
    "restaurant_profile = restaurant_profile.drop(columns=['Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>business_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "      <th>liked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AqPFMleE6RsU23_auESxiA</td>\n",
       "      <td>_7bHUi9Uuf5__HHc_Q8guQ</td>\n",
       "      <td>kxX2SOes4o-D3ZQBkiMRfA</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Wow!  Yummy, different,  delicious.   Our favo...</td>\n",
       "      <td>2015-01-04 00:01:03</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>oyaMhzBSwfGgemSGuZCdwQ</td>\n",
       "      <td>Dd1jQj7S-BFGqRbApFzCFw</td>\n",
       "      <td>YtSqYv1Q_pOltsVPSx54SA</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Tremendous service (Big shout out to Douglas) ...</td>\n",
       "      <td>2013-06-24 11:21:25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Xs8Z8lmKkosqW5mw_sVAoA</td>\n",
       "      <td>IQsF3Rc6IgCzjVV9DE8KXg</td>\n",
       "      <td>eFvzHawVJofxSnD7TgbZtg</td>\n",
       "      <td>5.0</td>\n",
       "      <td>My absolute favorite cafe in the city. Their b...</td>\n",
       "      <td>2014-11-12 15:30:27</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>JBWZmBy69VMggxj3eYn17Q</td>\n",
       "      <td>aFa96pz67TwOFu4Weq5Agg</td>\n",
       "      <td>kq5Ghhh14r-eCxlVmlyd8w</td>\n",
       "      <td>5.0</td>\n",
       "      <td>My boyfriend and I tried this deli for the fir...</td>\n",
       "      <td>2018-08-23 21:39:38</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>YcLXh-3UC9y6YFAI9xxzPQ</td>\n",
       "      <td>G0DHgkSsDozqUPWtlxVEMw</td>\n",
       "      <td>oBhJuukGRqPVvYBfTkhuZA</td>\n",
       "      <td>4.0</td>\n",
       "      <td>The only reason I didn't give this restaurant ...</td>\n",
       "      <td>2015-03-05 03:37:54</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6990235</th>\n",
       "      <td>ZcEx4UEnTnR_TEPEqwkKjA</td>\n",
       "      <td>gkg9VqsxPCgpfYXO1dl8CA</td>\n",
       "      <td>Ea663rIHyKXz2VP2DPH7Cg</td>\n",
       "      <td>4.0</td>\n",
       "      <td>I decided to try this place out after Christma...</td>\n",
       "      <td>2020-01-13 04:21:38</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6990239</th>\n",
       "      <td>me7QTotYCOjWNVA8bzN1eg</td>\n",
       "      <td>bJ5FtCtZX3ZZacz2_2PJjA</td>\n",
       "      <td>wMQkdK2aNMvq2xoojC98Mw</td>\n",
       "      <td>4.0</td>\n",
       "      <td>South Street Diner isn't the best of Philly Di...</td>\n",
       "      <td>2007-07-27 20:12:11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6990240</th>\n",
       "      <td>5n_oSwXspiiSsZgNwjp48g</td>\n",
       "      <td>bJ5FtCtZX3ZZacz2_2PJjA</td>\n",
       "      <td>SOsjW1JARmtHUFtpFlp8rw</td>\n",
       "      <td>4.0</td>\n",
       "      <td>When I first heard that the Peace A Pizza (htt...</td>\n",
       "      <td>2017-02-23 19:11:04</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6990255</th>\n",
       "      <td>MVg4YUQeEhCA7Z7RsBJSVg</td>\n",
       "      <td>7-7A0Avj47slLGV7yBFc8w</td>\n",
       "      <td>ytynqOUb3hjKeJfRj5Tshw</td>\n",
       "      <td>3.0</td>\n",
       "      <td>I was so excited about all the food I saw, but...</td>\n",
       "      <td>2013-07-25 21:00:15</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6990260</th>\n",
       "      <td>nLjbVsETpqO17RbFcqskkA</td>\n",
       "      <td>am7-gkH_PDz598oTdYSD6A</td>\n",
       "      <td>3gVSrS4kffGGZT8oXHsIcw</td>\n",
       "      <td>3.0</td>\n",
       "      <td>*Later Yelp* I've only been here once, but I l...</td>\n",
       "      <td>2014-11-03 14:45:46</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>511138 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      review_id                 user_id  \\\n",
       "3        AqPFMleE6RsU23_auESxiA  _7bHUi9Uuf5__HHc_Q8guQ   \n",
       "16       oyaMhzBSwfGgemSGuZCdwQ  Dd1jQj7S-BFGqRbApFzCFw   \n",
       "19       Xs8Z8lmKkosqW5mw_sVAoA  IQsF3Rc6IgCzjVV9DE8KXg   \n",
       "38       JBWZmBy69VMggxj3eYn17Q  aFa96pz67TwOFu4Weq5Agg   \n",
       "42       YcLXh-3UC9y6YFAI9xxzPQ  G0DHgkSsDozqUPWtlxVEMw   \n",
       "...                         ...                     ...   \n",
       "6990235  ZcEx4UEnTnR_TEPEqwkKjA  gkg9VqsxPCgpfYXO1dl8CA   \n",
       "6990239  me7QTotYCOjWNVA8bzN1eg  bJ5FtCtZX3ZZacz2_2PJjA   \n",
       "6990240  5n_oSwXspiiSsZgNwjp48g  bJ5FtCtZX3ZZacz2_2PJjA   \n",
       "6990255  MVg4YUQeEhCA7Z7RsBJSVg  7-7A0Avj47slLGV7yBFc8w   \n",
       "6990260  nLjbVsETpqO17RbFcqskkA  am7-gkH_PDz598oTdYSD6A   \n",
       "\n",
       "                    business_id  stars  \\\n",
       "3        kxX2SOes4o-D3ZQBkiMRfA    5.0   \n",
       "16       YtSqYv1Q_pOltsVPSx54SA    5.0   \n",
       "19       eFvzHawVJofxSnD7TgbZtg    5.0   \n",
       "38       kq5Ghhh14r-eCxlVmlyd8w    5.0   \n",
       "42       oBhJuukGRqPVvYBfTkhuZA    4.0   \n",
       "...                         ...    ...   \n",
       "6990235  Ea663rIHyKXz2VP2DPH7Cg    4.0   \n",
       "6990239  wMQkdK2aNMvq2xoojC98Mw    4.0   \n",
       "6990240  SOsjW1JARmtHUFtpFlp8rw    4.0   \n",
       "6990255  ytynqOUb3hjKeJfRj5Tshw    3.0   \n",
       "6990260  3gVSrS4kffGGZT8oXHsIcw    3.0   \n",
       "\n",
       "                                                      text  \\\n",
       "3        Wow!  Yummy, different,  delicious.   Our favo...   \n",
       "16       Tremendous service (Big shout out to Douglas) ...   \n",
       "19       My absolute favorite cafe in the city. Their b...   \n",
       "38       My boyfriend and I tried this deli for the fir...   \n",
       "42       The only reason I didn't give this restaurant ...   \n",
       "...                                                    ...   \n",
       "6990235  I decided to try this place out after Christma...   \n",
       "6990239  South Street Diner isn't the best of Philly Di...   \n",
       "6990240  When I first heard that the Peace A Pizza (htt...   \n",
       "6990255  I was so excited about all the food I saw, but...   \n",
       "6990260  *Later Yelp* I've only been here once, but I l...   \n",
       "\n",
       "                        date  liked  \n",
       "3        2015-01-04 00:01:03      1  \n",
       "16       2013-06-24 11:21:25      1  \n",
       "19       2014-11-12 15:30:27      1  \n",
       "38       2018-08-23 21:39:38      1  \n",
       "42       2015-03-05 03:37:54      1  \n",
       "...                      ...    ...  \n",
       "6990235  2020-01-13 04:21:38      1  \n",
       "6990239  2007-07-27 20:12:11      1  \n",
       "6990240  2017-02-23 19:11:04      1  \n",
       "6990255  2013-07-25 21:00:15      0  \n",
       "6990260  2014-11-03 14:45:46      0  \n",
       "\n",
       "[511138 rows x 7 columns]"
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_review_filadelfia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [],
   "source": [
    "# counts\n",
    "user_counts = df_review_filadelfia['user_id'].value_counts()\n",
    "restaurant_counts = df_review_filadelfia['business_id'].value_counts()\n",
    "\n",
    "# creating filters for users and restaurants with 5+ reviews\n",
    "users_with_5_plus_reviews = user_counts[user_counts >= 5].index\n",
    "restaurants_with_5_plus_reviews = restaurant_counts[restaurant_counts >= 5].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of users with 5+ reviews: 13948\n",
      "Number of restaurants reviewed 5+ times: 3040\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of users with 5+ reviews: {len(users_with_5_plus_reviews)}')\n",
    "print(f'Number of restaurants reviewed 5+ times: {len(restaurants_with_5_plus_reviews)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0464826958020617"
      ]
     },
     "execution_count": 402,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Desired dataset shape\n",
    "#data = df_review_filadelfia_profiles[['user_id', 'business_id', 'text', 'stars']] # only positive reviews\n",
    "data = df_review_filadelfia[['user_id', 'business_id', 'text', 'stars']]\n",
    "\n",
    "data_sample = data.sample(100000, random_state=10).reset_index(drop=True)\n",
    "\n",
    "# train-test split\n",
    "X_train, X_test, y_train, y_test = skl_train_test_split(data_sample[['user_id', 'business_id', 'text']], data_sample['stars'], test_size=0.2, random_state=1)\n",
    "X_train.reset_index(drop=True, inplace=True)\n",
    "X_test.reset_index(drop=True, inplace=True)\n",
    "y_train.reset_index(drop=True, inplace=True)\n",
    "y_test.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# this outputs the topic matrix according to the method chosen (bag-of-word, lsa, lda and doc2vec) \n",
    "n_components = 8\n",
    "topic_matrix = feature_engineering(X_train, 'lda', n_components)\n",
    "\n",
    "# attach topic matrix to the dataset\n",
    "column_names = ['comp_{}'.format(i+1) for i in range(n_components)]\n",
    "topics = pd.DataFrame(topic_matrix, columns=column_names)\n",
    "\n",
    "# create profiles\n",
    "user_profile = pd.concat([X_train, topics], axis=1).drop(columns=['business_id', 'text']).groupby(\"user_id\", as_index=False)[column_names].mean()\n",
    "restaurant_profile = pd.concat([X_train, topics], axis=1).drop(columns=['user_id', 'text']).groupby(\"business_id\", as_index=False)[column_names].mean()\n",
    "\n",
    "# filtering for the ones with 5+ reviews (more representative)\n",
    "user_profile = user_profile[user_profile['user_id'].isin(users_with_5_plus_reviews)].reset_index(drop=True)\n",
    "restaurant_profile = restaurant_profile[restaurant_profile['business_id'].isin(restaurants_with_5_plus_reviews)].reset_index(drop=True)\n",
    "\n",
    "# predicting on the test set using the recommendations function\n",
    "X_test['star_pred'] = X_test.apply(lambda row: recommend(row['user_id'], row['business_id'], df_review_filadelfia, user_profile, restaurant_profile, type='users'), axis=1)\n",
    "y = pd.concat([X_test['star_pred'], y_test], axis=1).dropna()\n",
    "\n",
    "# metrics\n",
    "np.sqrt(mean_squared_error(y['star_pred'], y['stars']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.273092206852342"
      ]
     },
     "execution_count": 403,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# função para dar input de user e business e output de rating (recomendações)\n",
    "X_test['star_pred'] = X_test.apply(lambda row: recommend(row['user_id'], row['business_id'], df_review_filadelfia, user_profile, restaurant_profile, type='items'), axis=1)\n",
    "y = pd.concat([X_test['star_pred'], y_test], axis=1).dropna()\n",
    "\n",
    "# avaliar no rating ground truth\n",
    "np.sqrt(mean_squared_error(y['star_pred'], y['stars']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1661959908374837"
      ]
     },
     "execution_count": 405,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# função para dar input de user e business e output de rating (recomendações)\n",
    "X_test['star_pred'] = X_test.apply(lambda row: recommend(row['user_id'], row['business_id'], df_review_filadelfia, user_profile, restaurant_profile, type='user_item'), axis=1)\n",
    "y = pd.concat([X_test['star_pred'], y_test], axis=1).dropna()\n",
    "\n",
    "# avaliar no rating ground truth\n",
    "np.sqrt(mean_squared_error(y['star_pred'], y['stars']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0464826958020617"
      ]
     },
     "execution_count": 406,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# função para dar input de user e business e output de rating (recomendações)\n",
    "X_test['star_pred'] = X_test.apply(lambda row: recommend(row['user_id'], row['business_id'], df_review_filadelfia, user_profile, restaurant_profile, type='users'), axis=1)\n",
    "y = pd.concat([X_test['star_pred'], y_test], axis=1).dropna()\n",
    "\n",
    "# avaliar no rating ground truth\n",
    "np.sqrt(mean_squared_error(y['star_pred'], y['stars']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_rating(cosine_similarity):\n",
    "    '''\n",
    "    Maps a consine similarity score to a rating from 1 to 5\n",
    "    '''\n",
    "    return 1 + 4 * ((cosine_similarity + 1) / 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load data\n",
    "\n",
    "def load_data():\n",
    "    # df_business = pd.read_csv('yelp_academic_dataset_business.csv')\n",
    "    # df_review=pd.read_csv('yelp_academic_dataset_review.csv')\n",
    "    # df_user=pd.read_csv('yelp_academic_dataset_user.csv')\n",
    "    \n",
    "    df_business_filadelfia = df_business[(df_business['city'] == 'Philadelphia') & (df_business['categories'].str.contains('Restaurants', na=False)) & (df_business['is_open']==1)].reset_index(drop=True)\n",
    "    df_business_filadelfia=df_business_filadelfia[['business_id', 'name', 'stars', 'review_count', 'attributes', 'categories', 'hours']].reset_index(drop=True)\n",
    "    df_business_filadelfia = df_business_filadelfia.dropna().reset_index(drop=True)\n",
    "\n",
    "    df_review_filadelfia = df_review[df_review['business_id'].isin(df_business_filadelfia['business_id'])]\n",
    "    df_review_filadelfia=df_review_filadelfia[['review_id', 'user_id', 'business_id', 'stars', 'text', 'date']]\n",
    "    df_review_filadelfia['liked'] = (df_review_filadelfia['stars'] > 3).astype(int)\n",
    "    df_review_filadelfia_profiles = df_review_filadelfia[df_review_filadelfia['liked'] == 1].reset_index(drop=True)\n",
    "    df_review_filadelfia = df_review_filadelfia.dropna().reset_index(drop=True)\n",
    "\n",
    "    df_user_filadelfia = df_user[df_user['user_id'].isin(df_review_filadelfia['user_id'])]\n",
    "    df_user_filadelfia=df_user_filadelfia[['user_id', 'name', 'review_count', 'yelping_since', 'elite', 'average_stars']].reset_index(drop=True)\n",
    "    df_user_filadelfia = df_user_filadelfia.dropna().reset_index(drop=True)\n",
    "\n",
    "    # counts\n",
    "    user_counts = df_review_filadelfia['user_id'].value_counts()\n",
    "    restaurant_counts = df_review_filadelfia['business_id'].value_counts()\n",
    "\n",
    "    # creating filters for users and restaurants with 5+ reviews\n",
    "    users_with_5_plus_reviews = user_counts[user_counts >= 5].index\n",
    "    restaurants_with_5_plus_reviews = restaurant_counts[restaurant_counts >= 5].index\n",
    "\n",
    "    return df_business_filadelfia,df_review_filadelfia,df_user_filadelfia, users_with_5_plus_reviews, restaurants_with_5_plus_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    words = text.split()\n",
    "    lemmatized_words = [lemmatizer.lemmatize(word) for word in words if word not in stop_words]\n",
    "    return ' '.join(lemmatized_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def stem_text(text):\n",
    "    words = text.split()\n",
    "    stemmed_words = [stemmer.stem(word) for word in words if word not in stop_words]\n",
    "    return ' '.join(stemmed_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pre-processamento\n",
    "def pre_processing(data_review,method):\n",
    "    if method == 'with lemma':\n",
    "\n",
    "        data_review['text'] = data_review['text'].apply(lemmatize_text)\n",
    "\n",
    "    \n",
    "    else: \n",
    "        data_review['text'] = data_review['text'].apply(stem_text)\n",
    "\n",
    "    return data_review\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature Engineering\n",
    "def feature_engineering(data_reviews, method, components=8):\n",
    "    if method == 'bag of words':\n",
    "        vectorizer = CountVectorizer(max_df=0.95, min_df=2)\n",
    "        matrix = vectorizer.fit_transform(data_reviews['text'])\n",
    "        matrix = matrix.toarray()\n",
    "        components = matrix.shape[1]\n",
    "        # feature_names = vectorizer.get_feature_names_out()\n",
    "        # df = pd.DataFrame(matrix, columns=feature_names)\n",
    "   \n",
    "    elif method =='lda':\n",
    "        count_vectorizer = CountVectorizer(max_df=0.95, min_df=2)\n",
    "        count_matrix = count_vectorizer.fit_transform(data_reviews['text'])\n",
    "        lda_model = LatentDirichletAllocation(n_components=components, random_state=42)\n",
    "        matrix = lda_model.fit_transform(count_matrix)\n",
    "        # df = pd.DataFrame(matrix, columns=[f'Topic_{i}' for i in range(lda_model.n_components)])\n",
    "    \n",
    "    elif method =='lsa':\n",
    "        vectorizer = CountVectorizer()\n",
    "        count_matrix = vectorizer.fit_transform(data_reviews['text'])\n",
    "        lsa_model = TruncatedSVD(n_components=components)\n",
    "        matrix = lsa_model.fit_transform(count_matrix)\n",
    "\n",
    "    elif method == 'doc2vec':\n",
    "        # preproces the documents, and create TaggedDocuments\n",
    "        tagged_data = [TaggedDocument(words=word_tokenize(doc.lower()),\n",
    "                                    tags=[str(i)]) for i,\n",
    "                    doc in enumerate(data_reviews['text'])]\n",
    "\n",
    "        # Doc2vec model\n",
    "        model = Doc2Vec(vector_size=components,\n",
    "                        min_count=2, epochs=50)\n",
    "        model.build_vocab(tagged_data)\n",
    "        model.train(tagged_data,\n",
    "                    total_examples=model.corpus_count,\n",
    "                    epochs=model.epochs)\n",
    "\n",
    "        # document vectors\n",
    "        matrix = [model.infer_vector(\n",
    "            word_tokenize(doc.lower())) for doc in data_reviews['text']]\n",
    "\n",
    "    return matrix, components\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def features_business(df_business_filadelfia):\n",
    "    df_business_filadelfia = df_business_filadelfia[['business_id', 'name', 'stars', 'review_count','attributes', 'categories', 'hours']]\n",
    "\n",
    "\n",
    "    #variavel horario\n",
    "    df_business_filadelfia['hours'] = df_business_filadelfia['hours'].apply(lambda x: ast.literal_eval(x) if pd.notnull(x) else {})\n",
    "\n",
    "    # Crie colunas separadas para cada dia da semana\n",
    "    dias_da_semana = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "\n",
    "    for dia in dias_da_semana:\n",
    "        df_business_filadelfia[dia] = df_business_filadelfia['hours'].apply(lambda x: x.get(dia, None))\n",
    "\n",
    "    # Remova a coluna original 'hours' se não for mais necessária\n",
    "    df_business_filadelfia.drop(columns=['hours'], inplace=True)\n",
    "\n",
    "\n",
    "    def categorize_hours(hours):\n",
    "\n",
    "        if hours == None:\n",
    "            return 0 #'Fechado'\n",
    "        \n",
    "        else:\n",
    "            start_time, end_time = hours.split('-')\n",
    "            start_hour = int(start_time.split(':')[0])\n",
    "            end_hour = int(end_time.split(':')[0])\n",
    "            \n",
    "            if end_hour <= 12:\n",
    "                return 1 #'Manhã'\n",
    "            elif 12 < start_hour and end_hour<=15:\n",
    "                return 2 #'Almoço'\n",
    "            elif start_hour > 15 and end_hour < 19:\n",
    "                return 3 #'Tarde'\n",
    "            elif start_hour>=19:\n",
    "                return 4 #'Noite'\n",
    "            else:\n",
    "                return 5 #'Dia todo'\n",
    "\n",
    "    # Aplicar a função de categorização a cada coluna de dia da semana\n",
    "    for day in ['Monday', 'Tuesday', 'Wednesday','Thursday', 'Friday', 'Saturday', 'Sunday']:\n",
    "        df_business_filadelfia[day] = df_business_filadelfia[day].apply(categorize_hours)\n",
    "\n",
    "\n",
    "    #variavel categoria\n",
    "\n",
    "    df_business_filadelfia['Restaurants'] = 0\n",
    "    df_business_filadelfia['Food'] = 0\n",
    "    df_business_filadelfia['Nightlife'] = 0\n",
    "    df_business_filadelfia['Bars'] = 0\n",
    "    df_business_filadelfia['Sandwiches'] = 0\n",
    "    df_business_filadelfia['American (New)'] = 0\n",
    "    df_business_filadelfia['Pizza'] = 0\n",
    "    df_business_filadelfia['Breakfast & Brunch'] = 0\n",
    "    df_business_filadelfia['American (Traditional)'] = 0\n",
    "    df_business_filadelfia['Coffee & Tea'] = 0\n",
    "\n",
    "    for index, row in df_business_filadelfia.iterrows():\n",
    "        categories = row['categories']\n",
    "        if 'Restaurants' in categories:\n",
    "            df_business_filadelfia.at[index, 'Restaurantes'] = 1\n",
    "\n",
    "        if 'Food' in categories:\n",
    "            df_business_filadelfia.at[index, 'Food'] = 1\n",
    "\n",
    "        if 'Nightlife' in categories:\n",
    "            df_business_filadelfia.at[index, 'Nightlife'] = 1\n",
    "\n",
    "        if 'Bars' in categories:\n",
    "            df_business_filadelfia.at[index, 'Bars'] = 1\n",
    "\n",
    "        if 'Sandwiches' in categories:\n",
    "            df_business_filadelfia.at[index, 'Sandwiches'] = 1\n",
    "\n",
    "        if 'American (New)' in categories:\n",
    "            df_business_filadelfia.at[index, 'American (New)'] = 1\n",
    "        \n",
    "        if 'Pizza' in categories:\n",
    "            df_business_filadelfia.at[index, 'Pizza'] = 1\n",
    "\n",
    "        if 'Breakfast & Brunch' in categories:\n",
    "            df_business_filadelfia.at[index, 'Breakfast & Brunch'] = 1\n",
    "\n",
    "        if 'American (Traditional)' in categories:\n",
    "            df_business_filadelfia.at[index, 'American (Traditional)'] = 1\n",
    "\n",
    "        if 'Coffee & Tea' in categories:\n",
    "            df_business_filadelfia.at[index, 'Coffee & Tea'] = 1\n",
    "\n",
    "\n",
    "\n",
    "        #variavel atributos\n",
    "\n",
    "        df_business_filadelfia['RestaurantsDelivery'] = 0\n",
    "        df_business_filadelfia['OutdoorSeating'] = 0\n",
    "        df_business_filadelfia['BusinessAcceptsCreditCards'] = 0\n",
    "        df_business_filadelfia['BikeParking'] = 0\n",
    "        df_business_filadelfia['RestaurantsTakeOut'] = 0\n",
    "        df_business_filadelfia['ByAppointmentOnly'] = 0\n",
    "        df_business_filadelfia['Caters'] = 0\n",
    "        df_business_filadelfia['RestaurantsReservations'] = 0\n",
    "        df_business_filadelfia['RestaurantsGoodForGroups'] = 0\n",
    "        df_business_filadelfia['HasTV'] = 0\n",
    "        df_business_filadelfia['GoodForKids'] = 0\n",
    "        df_business_filadelfia['DogsAllowed'] = 0\n",
    "        df_business_filadelfia['HappyHour'] = 0\n",
    "        df_business_filadelfia['WheelchairAccessible'] = 0\n",
    "        df_business_filadelfia['RestaurantsTableService'] = 0\n",
    "        df_business_filadelfia['BusinessAcceptsBitcoin'] = 0\n",
    "        df_business_filadelfia['Corkage'] = 0\n",
    "        df_business_filadelfia['CoatCheck'] = 0\n",
    "        df_business_filadelfia['BYOB'] = 0\n",
    "        df_business_filadelfia['DriveThru'] = 0\n",
    "\n",
    "\n",
    "        for index, row in df_business_filadelfia.iterrows():\n",
    "            categories = row['categories']\n",
    "            if 'RestaurantsDelivery' in categories:\n",
    "                df_business_filadelfia.at[index, 'RestaurantsDelivery'] = 1\n",
    "\n",
    "            if 'OutdoorSeating' in categories:\n",
    "                df_business_filadelfia.at[index, 'OutdoorSeating'] = 1\n",
    "\n",
    "            if 'BusinessAcceptsCreditCards' in categories:\n",
    "                df_business_filadelfia.at[index, 'BusinessAcceptsCreditCards'] = 1\n",
    "\n",
    "            if 'BikeParking' in categories:\n",
    "                df_business_filadelfia.at[index, 'BikeParking'] = 1\n",
    "\n",
    "            if 'RestaurantsTakeOut' in categories:\n",
    "                df_business_filadelfia.at[index, 'RestaurantsTakeOut'] = 1\n",
    "\n",
    "            if 'ByAppointmentOnly' in categories:\n",
    "                df_business_filadelfia.at[index, 'ByAppointmentOnly'] = 1\n",
    "            \n",
    "            if 'Caters' in categories:\n",
    "                df_business_filadelfia.at[index, 'Caters'] = 1\n",
    "\n",
    "            if 'RestaurantsReservations' in categories:\n",
    "                df_business_filadelfia.at[index, 'RestaurantsReservations'] = 1\n",
    "\n",
    "            if 'RestaurantsGoodForGroups' in categories:\n",
    "                df_business_filadelfia.at[index, 'RestaurantsGoodForGroups'] = 1\n",
    "\n",
    "            if 'HasTV' in categories:\n",
    "                df_business_filadelfia.at[index, 'HasTV'] = 1\n",
    "\n",
    "            if 'GoodForKids' in categories:\n",
    "                df_business_filadelfia.at[index, 'GoodForKids'] = 1\n",
    "\n",
    "            if 'DogsAllowed' in categories:\n",
    "                df_business_filadelfia.at[index, 'DogsAllowed'] = 1\n",
    "\n",
    "            if 'HappyHour' in categories:\n",
    "                df_business_filadelfia.at[index, 'HappyHour'] = 1\n",
    "\n",
    "            if 'WheelchairAccessible' in categories:\n",
    "                df_business_filadelfia.at[index, 'WheelchairAccessible'] = 1\n",
    "\n",
    "            if 'RestaurantsTableService' in categories:\n",
    "                df_business_filadelfia.at[index, 'RestaurantsTableService'] = 1\n",
    "\n",
    "            if 'BusinessAcceptsBitcoin' in categories:\n",
    "                df_business_filadelfia.at[index, 'BusinessAcceptsBitcoin'] = 1\n",
    "\n",
    "            if 'Corkage' in categories:\n",
    "                df_business_filadelfia.at[index, 'Corkage'] = 1\n",
    "            \n",
    "            if 'CoatCheck' in categories:\n",
    "                df_business_filadelfia.at[index, 'CoatCheck'] = 1\n",
    "\n",
    "            if 'BYOB' in categories:\n",
    "                df_business_filadelfia.at[index, 'BYOB'] = 1\n",
    "\n",
    "            if 'DriveThru' in categories:\n",
    "                df_business_filadelfia.at[index, 'DriveThru'] = 1\n",
    "\n",
    "        df_business_filadelfia.columns = ['business_id', 'name', 'stars', 'review_count_business', 'attributes', 'categories', 'Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday',\n",
    "       'Saturday', 'Sunday', 'Restaurants', 'Food', 'Nightlife', 'Bars', 'Sandwiches', 'American (New)', 'Pizza', 'Breakfast & Brunch', 'American (Traditional)', 'Coffee & Tea', 'Restaurantes',\n",
    "       'RestaurantsDelivery', 'OutdoorSeating', 'BusinessAcceptsCreditCards', 'BikeParking', 'RestaurantsTakeOut', 'ByAppointmentOnly', 'Caters','RestaurantsReservations', 'RestaurantsGoodForGroups', 'HasTV',\n",
    "       'GoodForKids', 'DogsAllowed', 'HappyHour', 'WheelchairAccessible','RestaurantsTableService', 'BusinessAcceptsBitcoin', 'Corkage','CoatCheck', 'BYOB', 'DriveThru']\n",
    "        \n",
    "        df_business_filadelfia=df_business_filadelfia.drop(['attributes', 'categories','name'],axis=1)\n",
    "\n",
    "        return df_business_filadelfia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def features_user(df_user_filadelfia):\n",
    "\n",
    "\n",
    "    yelping_since = pd.to_datetime(df_user_filadelfia['yelping_since'])\n",
    "\n",
    "    # Calcule o número de anos no Yelp\n",
    "    current_year = datetime.now().year\n",
    "    df_user_filadelfia['yelping_since'] = current_year - yelping_since.dt.year\n",
    "\n",
    "\n",
    "    df_user_filadelfia.columns = ['user_id', 'name', 'review_count_user', 'yelping_years', 'elite', 'average_stars']\n",
    "    df_user_filadelfia=df_user_filadelfia.drop(['elite','name'],axis=1)\n",
    "    # df_user_filadelfia=df_user_filadelfia.drop('yelping_since',axis=1)\n",
    "\n",
    "        \n",
    "\n",
    "    return df_user_filadelfia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def profiling(X_train, method, n_components, users_with_5_plus_reviews, restaurants_with_5_plus_reviews):\n",
    "    \n",
    "    # this outputs the topic matrix according to the method chosen (bag-of-word, lsa, lda and doc2vec) \n",
    "    topic_matrix, n_components = feature_engineering(X_train, method, n_components)\n",
    "\n",
    "    # attach topic matrix to the dataset\n",
    "    column_names = ['comp_{}'.format(i+1) for i in range(n_components)]\n",
    "    topics = pd.DataFrame(topic_matrix, columns=column_names)\n",
    "\n",
    "    # create profiles\n",
    "    user_profile = pd.concat([X_train, topics], axis=1).drop(columns=['business_id', 'text']).groupby(\"user_id\", as_index=False)[column_names].mean()\n",
    "    restaurant_profile = pd.concat([X_train, topics], axis=1).drop(columns=['user_id', 'text']).groupby(\"business_id\", as_index=False)[column_names].mean()\n",
    "\n",
    "    # filtering for the ones with 5+ reviews (more representative)\n",
    "    user_profile = user_profile[user_profile['user_id'].isin(users_with_5_plus_reviews)].reset_index(drop=True)\n",
    "    restaurant_profile = restaurant_profile[restaurant_profile['business_id'].isin(restaurants_with_5_plus_reviews)].reset_index(drop=True)\n",
    "\n",
    "    return user_profile, restaurant_profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Divisão teste e treino\n",
    "#por enquanto está assim mas depois temos de definir como vamos querer dividir \n",
    "def split_data(final_data,business_data,users_data):\n",
    "\n",
    "    general_trainset, general_testset = train_test_split(final_data, test_size=0.20, random_state=42)\n",
    "\n",
    "    # Criar users_trainset e users_testset\n",
    "    users_trainset = users_data[users_data['user_id'].isin(general_trainset['user_id'])]\n",
    "    users_testset = users_data[users_data['user_id'].isin(general_testset['user_id'])]\n",
    "\n",
    "    # Criar business_trainset e business_testset\n",
    "    business_trainset = business_data[business_data['business_id'].isin(general_trainset['business_id'])]\n",
    "    business_testset = business_data[business_data['business_id'].isin(general_testset['business_id'])]\n",
    "\n",
    "    # Verificar os tamanhos dos conjuntos\n",
    "    print(\"Tamanho do trainset:\", len(general_trainset))\n",
    "    print(\"Tamanho do testset:\", len(general_testset))\n",
    "    print(\"Tamanho do users_trainset:\", len(users_trainset))\n",
    "    print(\"Tamanho do users_testset:\", len(users_testset))\n",
    "    print(\"Tamanho do business_trainset:\", len(business_trainset))\n",
    "    print(\"Tamanho do business_testset:\", len(business_testset))\n",
    "\n",
    "    return general_trainset, general_testset,users_trainset, users_testset,business_trainset, business_testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(df_review_filadelfia):\n",
    "    # Desired dataset shape\n",
    "    #data = df_review_filadelfia_profiles[['user_id', 'business_id', 'text', 'stars']] # only positive reviews\n",
    "    data = df_review_filadelfia[['user_id', 'business_id', 'text', 'stars']]\n",
    "\n",
    "    #data_sample = data.sample(100000, random_state=10).reset_index(drop=True)\n",
    "\n",
    "    # train-test split\n",
    "    X_train, X_test, y_train, y_test = skl_train_test_split(data[['user_id', 'business_id', 'text']], data['stars'], test_size=0.2, random_state=1)\n",
    "    X_train.reset_index(drop=True, inplace=True)\n",
    "    X_test.reset_index(drop=True, inplace=True)\n",
    "    y_train.reset_index(drop=True, inplace=True)\n",
    "    y_test.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_similar_restaurants(restaurant_id, philly_restaurants, similarity_matrix, n=5):\n",
    "    # Obter o índice do restaurante\n",
    "    idx = philly_restaurants.index[philly_restaurants['business_id'] == restaurant_id].tolist()[0]\n",
    "    \n",
    "    # Obter similaridade do restaurante com todos os outros\n",
    "    similars_indices = similarity_matrix[idx].argsort()[::-1]  # Do mais similar para o menos similar\n",
    "    \n",
    "    # Excluir o próprio restaurante da recomendação\n",
    "    similars_indices = similars_indices[similars_indices != idx]\n",
    "    \n",
    "    # Selecionar os n mais similares\n",
    "    similars_restaurants = philly_restaurants.iloc[similars_indices[:n]]\n",
    "    \n",
    "    return similars_restaurants[['business_id', 'name', 'categories', 'stars']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para recomendar com base nos restaurantes que o usuário já avaliou bem\n",
    "def recommend_for_user(user_id, philly_restaurants, algo, similarity_matrix, n=5):\n",
    "    # Obter os restaurantes avaliados pelo usuário\n",
    "    user_reviews = ratings[ratings['user_id'] == user_id]\n",
    "    highly_rated = user_reviews[user_reviews['stars'] >= 4]['business_id']\n",
    "    \n",
    "    # Para cada restaurante que o usuário gostou, recomendar restaurantes similares\n",
    "    recommendations = pd.DataFrame()\n",
    "    # print('highly rated ',highly_rated)\n",
    "\n",
    "    for restaurant_id in highly_rated:\n",
    "        try:\n",
    "            # Obter o índice do restaurante\n",
    "            inner_id = algo.trainset.to_inner_iid(restaurant_id)\n",
    "            \n",
    "            # Obter os restaurantes mais similares usando o modelo treinado\n",
    "            neighbors = algo.get_neighbors(inner_id, k=n)\n",
    "            # print('neighbors ',neighbors)\n",
    "            # Converter os índices internos para IDs de restaurantes\n",
    "            similar_restaurant_ids_knn = [algo.trainset.to_raw_iid(inner_id) for inner_id in neighbors]\n",
    "            \n",
    "            # Obter os detalhes dos restaurantes similares usando o modelo treinado\n",
    "            similar_restaurants_knn = philly_restaurants[philly_restaurants['business_id'].isin(similar_restaurant_ids_knn)]\n",
    "            # print('similar_restaurants_knn ',similar_restaurants_knn)\n",
    "        except ValueError:\n",
    "            # Se o restaurante não estiver no conjunto de treino, retornar um DataFrame vazio\n",
    "            similar_restaurants_knn = pd.DataFrame()\n",
    "        \n",
    "        # Obter os detalhes dos restaurantes similares usando a matriz de similaridade\n",
    "        similar_restaurants_matrix = recommend_similar_restaurants(restaurant_id, philly_restaurants, similarity_matrix, n)\n",
    "        # print('similar_restaurants_matrix ',similar_restaurants_matrix)\n",
    "        # Combinar as recomendações de ambos os métodos\n",
    "        combined_recommendations = pd.concat([similar_restaurants_knn, similar_restaurants_matrix]).drop_duplicates(subset='business_id')\n",
    "        \n",
    "        recommendations = pd.concat([recommendations, combined_recommendations])\n",
    "        # print('recommendations ',recommendations)\n",
    "    # Remover duplicatas e ordenar por popularidade (opcional: você pode melhorar o critério de ordenação)\n",
    "    recommendations = recommendations.drop_duplicates(subset='name').sort_values(by='stars', ascending=False)\n",
    "    # print('recommendations ',recommendations)\n",
    "    return recommendations['name'].head(n)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_n_similar_users(user_id, n,similarity_matrix,user_trainset):\n",
    "    if user_id in similarity_matrix.index:\n",
    "        similar_users = similarity_matrix[user_id].sort_values(ascending=False).index[1:n+1]\n",
    "    else:\n",
    "        from sklearn.neighbors import NearestNeighbors\n",
    "        knn = NearestNeighbors(n_neighbors=n, metric='cosine')\n",
    "        knn.fit(user_trainset)\n",
    "        distances, indices = knn.kneighbors(user_trainset.loc[user_id].values.reshape(1, -1), n_neighbors=n+1)\n",
    "        similar_users = user_trainset.index[indices.flatten()][1:]\n",
    "    return similar_users\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recommended_restaurants(user_id, similar_users, n,user_trainset):\n",
    "    target_user_ratings = user_trainset.loc[user_id]\n",
    "    target_user_visited = target_user_ratings[target_user_ratings > 0].index\n",
    "\n",
    "    similar_users_ratings = user_trainset.loc[similar_users]\n",
    "    similar_users_ratings = similar_users_ratings.drop(columns=target_user_visited, errors='ignore')\n",
    "\n",
    "    top_rated_restaurants = similar_users_ratings.mean().sort_values(ascending=False).head(n)\n",
    "    return top_rated_restaurants\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recommendation system\n",
    "\n",
    "def recommend(user_id, restaurant_id, df_review_filadelfia, user_profile, restaurant_profile, type='UIBH'):\n",
    "    \n",
    "    '''\n",
    "    Esstimates rating a user gives to a restaurant\n",
    "\n",
    "    Inputs:\n",
    "    user_id - the user\n",
    "    restaurant_id - the restaurant to be rated\n",
    "    df_review_filadelfia - original df with no filtering regarding the review being positive or not\n",
    "    user_profile - df with the profiles of the users (vectors from LSA/LDA/doc2vec)\n",
    "    restaurant_profile - df with the profiles of the restaurants (vectors from LSA/LDA/doc2vec)\n",
    "    type - type of recommendations (user_item, users or items) (default = \"user_item\")\n",
    "\n",
    "    Outputs:\n",
    "    Rating\n",
    "    '''\n",
    "\n",
    "    try:\n",
    "\n",
    "        # Extracting the vector relative to the user and removing the user from the profiles\n",
    "        usr_lst = user_profile[user_profile['user_id'] == user_id].drop(columns=['user_id']).values\n",
    "        user_profile_function = user_profile[user_profile['user_id'] != user_id].reset_index(drop=True)\n",
    "        \n",
    "        # Extracting the vector relative to the restaurant and removing the restaurant from the profiles\n",
    "        bus_lst = restaurant_profile[restaurant_profile['business_id'] == restaurant_id].drop(columns=['business_id']).values\n",
    "        restaurant_profile_function = restaurant_profile[restaurant_profile['business_id'] != restaurant_id].reset_index(drop=True)\n",
    "\n",
    "\n",
    "        if type == 'UIBH':\n",
    "            # Measures the similarity between user and restaurant\n",
    "            # Rating is a linear function of the similarity\n",
    "            similarity_score = cosine_similarity(usr_lst, bus_lst)\n",
    "            rating = map_rating(similarity_score[0][0])\n",
    "            \n",
    "        elif type == 'UBH':\n",
    "            # Measures the similarity between the user and the other users that rated the restaurant\n",
    "            # Rating is a weighted average of the ratings given by the users (weighted by the similarity)\n",
    "\n",
    "            # Getting the other users that rated the restaurant and removing user\n",
    "            users = df_review_filadelfia[df_review_filadelfia['business_id'] == restaurant_id]['user_id']\n",
    "            users = users[users != user_id]\n",
    "\n",
    "            # Due to considering only the positive reviews for the profiles, some users don't have profile\n",
    "            # This is to remove them from the users list\n",
    "            users = users[users.isin(user_profile_function['user_id'])].unique() # and remove duplicates\n",
    "\n",
    "            # Getting the ratings given by the users and averaging if there are more than one\n",
    "            users_ratings = df_review_filadelfia[df_review_filadelfia['user_id'].isin(users)][['user_id', 'stars']]\n",
    "            users_ratings = users_ratings.groupby('user_id').mean().reset_index()\n",
    "\n",
    "            # Creating a matrix for the similar users\n",
    "            user_matrix = user_profile_function[user_profile_function['user_id'].isin(users)].drop(columns=['user_id']).values\n",
    "\n",
    "            # Similarities between user and users\n",
    "            similarity_scores = cosine_similarity(usr_lst, user_matrix)\n",
    "\n",
    "            # Transform similarities into weights\n",
    "            # This assumes that there will be other similar users.\n",
    "            # If all the other users are not similar we are giving high weights to \"not similar\" users due to this rescaling\n",
    "            similarity_scores = (similarity_scores+1)/2\n",
    "            weights = similarity_scores / np.sum(similarity_scores, axis=1)\n",
    "\n",
    "            # Computing weight-averaged rating\n",
    "            rating = np.dot(weights[0], users_ratings['stars'])\n",
    "\n",
    "        elif type == 'IBH':\n",
    "            # Measures the similarity between the restaurant and other \n",
    "            # Recommends the restaurants that are most similar to the ones the user liked before\n",
    "\n",
    "            # Getting the other restaurants the user rated and removing the restaurant\n",
    "            restaurants = df_review_filadelfia[df_review_filadelfia['user_id'] == user_id]['business_id']\n",
    "            restaurants = restaurants[restaurants != restaurant_id]\n",
    "\n",
    "            # Due to considering only the positive reviews for the profiles, some restaurants don't have profile\n",
    "            # This is to remove them from the restaurants list\n",
    "            restaurants = restaurants[restaurants.isin(restaurant_profile_function['business_id'])].unique() # and remove duplicates\n",
    "\n",
    "            # Getting the ratings given by the user and averaging if there are more than one\n",
    "            user_ratings = df_review_filadelfia[df_review_filadelfia['user_id'] == user_id][['business_id', 'stars']]\n",
    "            user_ratings = user_ratings[user_ratings['business_id'].isin(restaurants)].reset_index(drop=True)\n",
    "            user_ratings = user_ratings.groupby('business_id').mean().reset_index()\n",
    "\n",
    "            # Creating a matrix for the similar restaurants\n",
    "            restaurant_matrix = restaurant_profile_function[restaurant_profile_function['business_id'].isin(restaurants)].drop(columns=['business_id']).values\n",
    "\n",
    "            # Similarities between the restaurant and the other restaurants\n",
    "            similarity_scores = cosine_similarity(bus_lst, restaurant_matrix)\n",
    "\n",
    "            # Transform similarities into weights\n",
    "            # This assumes that there will be other similar restaurants.\n",
    "            # If all the other restaurants are not similar we are giving high weights to \"not similar\" restaurants due to this rescaling\n",
    "            similarity_scores = (similarity_scores+1)/2\n",
    "            weights = similarity_scores / np.sum(similarity_scores, axis=1)\n",
    "\n",
    "            # Computing weight-averaged rating\n",
    "            rating = np.dot(weights[0], user_ratings['stars'])\n",
    "        \n",
    "        else:\n",
    "            raise ValueError(\"Invalid type. Please choose 'UIBH', 'UBH', or 'IBH'.\")\n",
    "        \n",
    "        return rating\n",
    "    \n",
    "    except:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_at_k(ground_truth, recommendations, k):\n",
    "\n",
    "    #top k predicted restaurants\n",
    "    top_k_pred = recommendations[:k]\n",
    "    \n",
    "    #top k user preferred restaurants\n",
    "    top_k_true = ground_truth[:k]\n",
    "    \n",
    "    # number of relevant items in the top k predictions\n",
    "    relevant = len(set(top_k_pred) & set(top_k_true))\n",
    "    \n",
    "    return relevant / k\n",
    "\n",
    "\n",
    "def recall_at_k(ground_truth, recommendations, k):\n",
    "\n",
    "    # top k predicted restaurants\n",
    "    top_k_pred = recommendations[:k]\n",
    "    \n",
    "    # total number of preferred restaurants\n",
    "    total_relevant = len(ground_truth)\n",
    "    \n",
    "    #number of relevant items in the top k predictions\n",
    "    relevant = len(set(top_k_pred) & set(ground_truth))\n",
    "    \n",
    "    return relevant / total_relevant if total_relevant > 0 else 0\n",
    "\n",
    "# TEMOS QUE APLICAR ISTO A CADA USER. TEMOS QUE TER UMA FUNÇÃO QUE PARA O USER DÁ TAMBÉM UM RANKING DE RESTAURANTES\n",
    "# COM ESSE RANKING CALCULAR PRECISION E RECALL @ K\n",
    "# E DEPOIS CALCULAR A MÉDIA DE TODOS OS USERS PARA ESSE MÉTODO\n",
    "\n",
    "# OU ENTÃO AGRUPAR AS PEDICTIONS POR USER E ASSUMIR ESSE RANKING\n",
    "# MARTELAR PARA SEREM SÓ USERS COM MAIS DE K REVIEWS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_evaluate(X_test, y_test, df_review_filadelfia, user_profile, restaurant_profile, method):\n",
    "    # predicting on the test set using the recommendations function\n",
    "    X_test['star_pred'] = X_test.apply(lambda row: recommend(row['user_id'], row['business_id'], df_review_filadelfia, user_profile, restaurant_profile, type=method), axis=1)\n",
    "    y = pd.concat([X_test['business_id'], X_test['star_pred'], y_test], axis=1).dropna()\n",
    "\n",
    "    # metrics\n",
    "    rmse = np.sqrt(mean_squared_error(y['star_pred'], y['stars']))\n",
    "\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "methods_pre_processing = ['with lemma','with stemma']\n",
    "# methods_feature_engineering = ['bag of words', 'word embeddings', 'lda']\n",
    "methods_feature_engineering = ['bag of words','lda', 'lsa', 'doc2vec']\n",
    "add_features_decision = ['yes','no']\n",
    "algorithms_cf = ['CF-UB','CF-IB'] #CF-IB(Colaborative Filtering Item Based),CF-UB(Colaborative Filtering User Based)\n",
    "algorithms_content = ['UBH','IBH','UIBH'] #UBH(User Based Hybrid), IBH(Item Based Hybrid), UIBH(User Item Based Hybrid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Main J\n",
    "rmse_df = pd.DataFrame(columns=['Pre-processing', 'Feature Engineering', 'Algorithm', 'RMSE'])\n",
    "\n",
    "def main():\n",
    "    # Load the dataset\n",
    "    df_business_filadelfia,df_review_filadelfia,df_user_filadelfia, users_with_5_plus_reviews, restaurants_with_5_plus_reviews = load_data()\n",
    "\n",
    "    # Train-test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df_review_filadelfia)\n",
    "\n",
    "    users_train = X_train['user_id']\n",
    "\n",
    "    businesses_train = X_train['business_id']\n",
    "\n",
    "    df_user_filadelfia_treino = df_user_filadelfia[df_user_filadelfia['user_id'].isin(users_train)]\n",
    "\n",
    "    df_business_filadelfia_treino = df_business_filadelfia[df_business_filadelfia['business_id'].isin(businesses_train)]\n",
    "\n",
    "    df_features_user = features_user(df_user_filadelfia_treino)\n",
    "    df_features_business = features_business(df_business_filadelfia_treino)\n",
    "\n",
    "    # Collaborative Filtering (ACHO QUE O SPLIT NÃO VAI FUNCIONAR PARA AQUI - ACHO QUE VALE A PENA TER UMA MAIN SÓ PARA O CF)\n",
    "    # for a in algorithms_cf:\n",
    "    #     if a == 'CF-UB':\n",
    "    #         algo = KNNBasic(sim_options={'user_based': True})\n",
    "    #         algo.fit(X_train)\n",
    "\n",
    "\n",
    "\n",
    "    #     else:\n",
    "\n",
    "    #         algo = KNNBasic(sim_options={'user_based': False})\n",
    "    #         algo.fit(X_train)\n",
    "\n",
    "    #     predictions = algo.test(X_test)\n",
    "    #     rmse = accuracy.rmse(predictions)\n",
    "        \n",
    "    # Content-based / Hybrid\n",
    "    for a in methods_pre_processing:\n",
    "        X_train_pre_processed = pre_processing(X_train, a)\n",
    "\n",
    "        for b in methods_feature_engineering:\n",
    "\n",
    "            if b == 'doc2vec':\n",
    "                n_components = 100\n",
    "            else:\n",
    "                n_components = 8\n",
    "\n",
    "\n",
    "            user_profile, restaurant_profile = profiling(X_train_pre_processed, b, n_components, users_with_5_plus_reviews, restaurants_with_5_plus_reviews)\n",
    "\n",
    "            user_profile=user_profile.merge(df_features_user,on='user_id')\n",
    "            restaurant_profile=restaurant_profile.merge(df_features_business,on='business_id')\n",
    "\n",
    "            for c in algorithms_content:\n",
    "\n",
    "                rmse = test_evaluate(X_test, y_test, df_review_filadelfia, user_profile, restaurant_profile, c)\n",
    "                rmse_df = rmse_df.append({'Pre-processing': a, 'Feature Engineering': b, 'Algorithm': c, 'RMSE': rmse}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Main\n",
    "feature_engineering_method = []\n",
    "algoritmo=[]\n",
    "accuracy = []\n",
    "precision = []\n",
    "f1_score = []\n",
    "recall = []\n",
    "\n",
    "def main():\n",
    "    df_business_filadelfia,df_review_filadelfia,df_user_filadelfia = load_data()\n",
    "\n",
    "    df_business_filadelfia=df_business_filadelfia.sample(1000)\n",
    "    df_review_filadelfia=df_review_filadelfia.sample(1000)\n",
    "    df_user_filadelfia=df_user_filadelfia.sample(1000)\n",
    "\n",
    "    for a in algorithms_cf:\n",
    "        if a == 'CF-UB':\n",
    "            algo = KNNBasic(sim_options={'user_based': True})\n",
    "            algo.fit(user_trainset)\n",
    "            predictions = algo.test(user_testset)\n",
    "\n",
    "        else:\n",
    "\n",
    "            algo = KNNBasic(sim_options={'user_based': False})\n",
    "            algo.fit(business_trainset)\n",
    "            predictions = algo.test(business_testset)  \n",
    "\n",
    "\n",
    "    for a in methods_pre_processing:\n",
    "        df_review_filadelfia_pre_processado = pre_processing(df_review_filadelfia,a)\n",
    "\n",
    "        for b in methods_feature_engineering:\n",
    "            matrix = feature_engineering(df_review_filadelfia_pre_processado,b)\n",
    "\n",
    "            for c in algorithms_content:\n",
    "                df_review_filadelfia = df_review_filadelfia.reset_index(drop=True)\n",
    "\n",
    "                if c == 'UBH':\n",
    "                    matrix_per_user = df_review_filadelfia.groupby('user_id').apply(lambda x: np.mean(matrix[x.index], axis=0))\n",
    "                    features = features_user(df_user_filadelfia)\n",
    "\n",
    "                    matrix_df = pd.DataFrame(matrix_per_user.tolist(), index=matrix_per_user.index)\n",
    "\n",
    "                    # Adiciona a coluna 'user_id' ao DataFrame\n",
    "                    matrix_df.reset_index(inplace=True)\n",
    "\n",
    "                    # Junta as features à matriz\n",
    "                    result_df = matrix_df.merge(features, on='user_id')\n",
    "\n",
    "                    result_matrix = result_df.set_index('user_id').to_numpy()\n",
    "\n",
    "                    similarity_matrix = cosine_similarity(result_matrix)\n",
    "\n",
    "                if c == 'IBH':\n",
    "                    matrix_per_business = df_review_filadelfia.groupby('business_id').apply(lambda x: np.mean(matrix[x.index], axis=0))\n",
    "                    features = features_business(df_business_filadelfia)\n",
    "\n",
    "                    matrix_df = pd.DataFrame(matrix_per_business.tolist(), index=matrix_per_business.index)\n",
    "\n",
    "                    # Adiciona a coluna 'business_id' ao DataFrame\n",
    "                    matrix_df.reset_index(inplace=True)\n",
    "\n",
    "                    # Junta as features à matriz\n",
    "                    result_df = matrix_df.merge(features, on='business_id')\n",
    "\n",
    "                    result_matrix = result_df.set_index('business_id').to_numpy()\n",
    "\n",
    "                    #há restaurantes na matriz que não têm info nas features, mas agora já não consigo pensar\n",
    "\n",
    "                    similarity_matrix = cosine_similarity(result_matrix)\n",
    "\n",
    "\n",
    "                return similarity_matrix\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.99544841, 0.9956561 , 0.99550571, 0.99320691,\n",
       "        0.99512158, 0.97249916, 0.99370598, 0.99560994, 0.99512402,\n",
       "        0.99566465, 0.99468465, 0.99510445, 0.99554181, 0.96953973,\n",
       "        0.99503323, 0.9954954 ],\n",
       "       [0.99544841, 1.        , 0.99861204, 0.99838974, 0.99591978,\n",
       "        0.99783472, 0.97700643, 0.99572167, 0.99871058, 0.99854622,\n",
       "        0.99869774, 0.99812797, 0.99797965, 0.99823546, 0.97154531,\n",
       "        0.99753358, 0.99831295],\n",
       "       [0.9956561 , 0.99861204, 1.        , 0.99958286, 0.99581111,\n",
       "        0.99938824, 0.97197443, 0.99640836, 0.9996102 , 0.99791619,\n",
       "        0.99928982, 0.99789648, 0.9978941 , 0.99941018, 0.96858762,\n",
       "        0.99865675, 0.99908913],\n",
       "       [0.99550571, 0.99838974, 0.99958286, 1.        , 0.99542662,\n",
       "        0.99978773, 0.96997742, 0.99636747, 0.99980537, 0.99736553,\n",
       "        0.99929694, 0.99763979, 0.99757971, 0.99964525, 0.96656999,\n",
       "        0.99882205, 0.99913428],\n",
       "       [0.99320691, 0.99591978, 0.99581111, 0.99542662, 1.        ,\n",
       "        0.99487779, 0.97450271, 0.9933151 , 0.9958191 , 0.99562086,\n",
       "        0.99595091, 0.99541835, 0.99558296, 0.99546823, 0.97000559,\n",
       "        0.99466321, 0.99557276],\n",
       "       [0.99512158, 0.99783472, 0.99938824, 0.99978773, 0.99487779,\n",
       "        1.        , 0.96757255, 0.99618468, 0.99963128, 0.99657858,\n",
       "        0.99894003, 0.99684643, 0.99690875, 0.99955955, 0.96492698,\n",
       "        0.99881262, 0.99891396],\n",
       "       [0.97249916, 0.97700643, 0.97197443, 0.96997742, 0.97450271,\n",
       "        0.96757255, 1.        , 0.97048659, 0.97125869, 0.9801121 ,\n",
       "        0.97352418, 0.97782985, 0.97697623, 0.97078765, 0.96870977,\n",
       "        0.96917797, 0.97255484],\n",
       "       [0.99370598, 0.99572167, 0.99640836, 0.99636747, 0.9933151 ,\n",
       "        0.99618468, 0.97048659, 1.        , 0.99651403, 0.99497372,\n",
       "        0.99651817, 0.99579263, 0.99490862, 0.99630712, 0.97043658,\n",
       "        0.99605613, 0.99604521],\n",
       "       [0.99560994, 0.99871058, 0.9996102 , 0.99980537, 0.9958191 ,\n",
       "        0.99963128, 0.97125869, 0.99651403, 1.        , 0.99773461,\n",
       "        0.99936958, 0.9978711 , 0.99776211, 0.9996193 , 0.96754144,\n",
       "        0.99877105, 0.99913725],\n",
       "       [0.99512402, 0.99854622, 0.99791619, 0.99736553, 0.99562086,\n",
       "        0.99657858, 0.9801121 , 0.99497372, 0.99773461, 1.        ,\n",
       "        0.99814986, 0.99800316, 0.9980508 , 0.99722176, 0.97373705,\n",
       "        0.99653565, 0.9977037 ],\n",
       "       [0.99566465, 0.99869774, 0.99928982, 0.99929694, 0.99595091,\n",
       "        0.99894003, 0.97352418, 0.99651817, 0.99936958, 0.99814986,\n",
       "        1.        , 0.99815482, 0.9981109 , 0.99915692, 0.97010877,\n",
       "        0.99834874, 0.99891306],\n",
       "       [0.99468465, 0.99812797, 0.99789648, 0.99763979, 0.99541835,\n",
       "        0.99684643, 0.97782985, 0.99579263, 0.9978711 , 0.99800316,\n",
       "        0.99815482, 1.        , 0.99764864, 0.99741142, 0.97348142,\n",
       "        0.99652877, 0.99761752],\n",
       "       [0.99510445, 0.99797965, 0.9978941 , 0.99757971, 0.99558296,\n",
       "        0.99690875, 0.97697623, 0.99490862, 0.99776211, 0.9980508 ,\n",
       "        0.9981109 , 0.99764864, 1.        , 0.99733874, 0.97182755,\n",
       "        0.99680413, 0.99756767],\n",
       "       [0.99554181, 0.99823546, 0.99941018, 0.99964525, 0.99546823,\n",
       "        0.99955955, 0.97078765, 0.99630712, 0.9996193 , 0.99722176,\n",
       "        0.99915692, 0.99741142, 0.99733874, 1.        , 0.96682889,\n",
       "        0.99873711, 0.99893571],\n",
       "       [0.96953973, 0.97154531, 0.96858762, 0.96656999, 0.97000559,\n",
       "        0.96492698, 0.96870977, 0.97043658, 0.96754144, 0.97373705,\n",
       "        0.97010877, 0.97348142, 0.97182755, 0.96682889, 1.        ,\n",
       "        0.96729074, 0.96910866],\n",
       "       [0.99503323, 0.99753358, 0.99865675, 0.99882205, 0.99466321,\n",
       "        0.99881262, 0.96917797, 0.99605613, 0.99877105, 0.99653565,\n",
       "        0.99834874, 0.99652877, 0.99680413, 0.99873711, 0.96729074,\n",
       "        1.        , 0.99834434],\n",
       "       [0.9954954 , 0.99831295, 0.99908913, 0.99913428, 0.99557276,\n",
       "        0.99891396, 0.97255484, 0.99604521, 0.99913725, 0.9977037 ,\n",
       "        0.99891306, 0.99761752, 0.99756767, 0.99893571, 0.96910866,\n",
       "        0.99834434, 1.        ]])"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main antiga"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Main\n",
    "feature_engineering_method = []\n",
    "algoritmo=[]\n",
    "accuracy = []\n",
    "precision = []\n",
    "f1_score = []\n",
    "recall = []\n",
    "\n",
    "def main():\n",
    "    df_business_filadelfia,df_review_filadelfia,df_user_filadelfia = load_data()\n",
    "\n",
    "    df_business_filadelfia=df_business_filadelfia.sample(1000)\n",
    "    df_review_filadelfia=df_review_filadelfia.sample(1000)\n",
    "    df_user_filadelfia=df_user_filadelfia.sample(1000)\n",
    "\n",
    "    for a in methods_pre_processing:\n",
    "        df_review_filadelfia_pre_processado = pre_processing(df_review_filadelfia,a)\n",
    "        # print(df_business_filadelfia)\n",
    "        # print(df_review_filadelfia)\n",
    "        # print(df_user_filadelfia)\n",
    "\n",
    "        for b in methods_feature_engineering:\n",
    "            feature_engineering_method.append(b)\n",
    "            final_data = feature_engineering(df_review_filadelfia_pre_processado,b)\n",
    "            # print(final_data)\n",
    "            for c in add_features_decision:\n",
    "                # print(a,b,c)\n",
    "                if c == 'yes':\n",
    "                    # business_data,users_data = add_features(final_data,df_business_filadelfia,df_review_filadelfia,df_user_filadelfia) #adicionamos as repetivas features a cada matriz\n",
    "                    colunas = add_features(final_data,df_business_filadelfia,df_review_filadelfia,df_user_filadelfia) #adicionamos as repetivas features a cada matriz\n",
    "                    print(colunas)\n",
    "                # else:\n",
    "                #     business_data=final_data\n",
    "                #     users_data=final_data\n",
    "                \n",
    "                # general_trainset, general_testset,user_trainset, user_testset,business_trainset, business_testset = split_data(final_data,business_data,users_data)\n",
    "\n",
    "                # print('general_trainset')\n",
    "                # print(general_trainset)\n",
    "\n",
    "                # print('general_testset')\n",
    "                # print(general_testset)\n",
    "\n",
    "                # print('user_trainset')\n",
    "                # print(user_trainset)\n",
    "\n",
    "                # print('user_testset')\n",
    "                # print(user_testset)\n",
    "\n",
    "                # print('business_trainset')\n",
    "                # print(business_trainset)\n",
    "\n",
    "                # print('business_testset')\n",
    "                # print(business_testset)\n",
    "\n",
    "    #             for d in algorithms:\n",
    "    #                 algoritmo.append(d)\n",
    "\n",
    "    #                 if d == 'CF-UB':\n",
    "    #                     algo = KNNBasic(sim_options={'user_based': True})\n",
    "    #                     algo.fit(user_trainset)\n",
    "    #                     predictions = algo.test(user_testset)\n",
    "\n",
    "    #                 elif d == 'CF-IB':\n",
    "    #                     algo = KNNBasic(sim_options={'user_based': False})\n",
    "    #                     algo.fit(business_trainset)\n",
    "    #                     predictions = algo.test(business_testset)\n",
    "\n",
    "    #                 elif d == 'UBH':\n",
    "    #                     similarity_matrix = cosine_similarity(user_trainset)\n",
    "    #                     similarity_matrix = pd.DataFrame(similarity_matrix, index=user_trainset.index, columns=user_trainset.index)\n",
    "\n",
    "    #                     for user_id in user_testset['user_id']:\n",
    "    #                         similar_users = get_top_n_similar_users(user_id, n=5)\n",
    "    #                         recommended_restaurants = get_recommended_restaurants(user_id, similar_users, n_restaurants=5)\n",
    "    #                         best_restaurant = recommended_restaurants.idxmax()\n",
    "\n",
    "\n",
    "    #                 elif d == 'IBH':\n",
    "    #                     for business_id in business_testset['business_id']:\n",
    "    #                         similarity_matrix = cosine_similarity(business_trainset)\n",
    "    #                         similarity_matrix = pd.DataFrame(similarity_matrix, index=business_trainset.index, columns=business_trainset.index)\n",
    "\n",
    "    #                         recommendations = recommend_for_user(user_id, philly_restaurants, algo, similarity_matrix, n=5)\n",
    "\n",
    "\n",
    "    #                 elif d == 'UIBH':\n",
    "    #                     similarity_matrix = cosine_similarity(user_trainset,business_trainset)\n",
    "    #                     similarity_matrix = pd.DataFrame(similarity_matrix, index=user_trainset.index, columns=business_trainset.index)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mecd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
