{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\helen\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\helen\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\helen\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import ast\n",
    "from surprise import Dataset, Reader, KNNBasic\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from surprise.model_selection import train_test_split\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\helen\\AppData\\Local\\Temp\\ipykernel_30980\\2274174141.py:7: DtypeWarning: Columns (8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_user=pd.read_csv('yelp_academic_dataset_user.csv')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['business_id', 'name', 'address', 'city', 'state', 'postal_code',\n",
      "       'latitude', 'longitude', 'stars', 'review_count', 'is_open',\n",
      "       'attributes', 'categories', 'hours'],\n",
      "      dtype='object')\n",
      "Index(['business_id', 'date'], dtype='object')\n",
      "Index(['review_id', 'user_id', 'business_id', 'stars', 'useful', 'funny',\n",
      "       'cool', 'text', 'date'],\n",
      "      dtype='object')\n",
      "Index(['user_id', 'business_id', 'text', 'date', 'compliment_count'], dtype='object')\n",
      "Index(['user_id', 'name', 'review_count', 'yelping_since', 'useful', 'funny',\n",
      "       'cool', 'elite', 'friends', 'fans', 'average_stars', 'compliment_hot',\n",
      "       'compliment_more', 'compliment_profile', 'compliment_cute',\n",
      "       'compliment_list', 'compliment_note', 'compliment_plain',\n",
      "       'compliment_cool', 'compliment_funny', 'compliment_writer',\n",
      "       'compliment_photos'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#Data\n",
    "\n",
    "df_business = pd.read_csv('yelp_academic_dataset_business.csv')\n",
    "df_checkin = pd.read_csv('yelp_academic_dataset_checkin.csv')\n",
    "df_review=pd.read_csv('yelp_academic_dataset_review.csv')\n",
    "df_tip=pd.read_csv('yelp_academic_dataset_tip.csv')\n",
    "df_user=pd.read_csv('yelp_academic_dataset_user.csv')\n",
    "\n",
    "print(df_business.columns)\n",
    "print(df_checkin.columns)\n",
    "print(df_review.columns)\n",
    "print(df_tip.columns)\n",
    "print(df_user.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Subset de dados\n",
    "\n",
    "df_business_filadelfia = df_business[(df_business['city'] == 'Philadelphia') & (df_business['categories'].str.contains('Restaurants', na=False)) & (df_business['is_open']==1)].reset_index(drop=True)\n",
    "df_business_filadelfia=df_business_filadelfia[['business_id', 'name', 'stars', 'review_count', 'attributes', 'categories', 'hours']]\n",
    "\n",
    "df_review_filadelfia = df_review[df_review['business_id'].isin(df_business_filadelfia['business_id'])]\n",
    "df_review_filadelfia=df_review_filadelfia[['review_id', 'user_id', 'business_id', 'stars', 'text', 'date']]\n",
    "\n",
    "df_user_filadelfia = df_user[df_user['user_id'].isin(df_review_filadelfia['user_id'])]\n",
    "df_user_filadelfia=df_user_filadelfia[['user_id', 'name', 'review_count', 'yelping_since', 'elite', 'average_stars']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load data\n",
    "\n",
    "def load_data():\n",
    "    # df_business = pd.read_csv('yelp_academic_dataset_business.csv')\n",
    "    # df_review=pd.read_csv('yelp_academic_dataset_review.csv')\n",
    "    # df_user=pd.read_csv('yelp_academic_dataset_user.csv')\n",
    "    \n",
    "    df_business_filadelfia = df_business[(df_business['city'] == 'Philadelphia') & (df_business['categories'].str.contains('Restaurants', na=False)) & (df_business['is_open']==1)].reset_index(drop=True)\n",
    "    df_business_filadelfia=df_business_filadelfia[['business_id', 'name', 'stars', 'review_count', 'attributes', 'categories', 'hours']]\n",
    "    df_business_filadelfia = df_business_filadelfia.dropna()\n",
    "\n",
    "    df_review_filadelfia = df_review[df_review['business_id'].isin(df_business_filadelfia['business_id'])]\n",
    "    df_review_filadelfia=df_review_filadelfia[['review_id', 'user_id', 'business_id', 'stars', 'text', 'date']]\n",
    "    df_review_filadelfia = df_review_filadelfia.dropna()\n",
    "\n",
    "    df_user_filadelfia = df_user[df_user['user_id'].isin(df_review_filadelfia['user_id'])]\n",
    "    df_user_filadelfia=df_user_filadelfia[['user_id', 'name', 'review_count', 'yelping_since', 'elite', 'average_stars']]\n",
    "    df_user_filadelfia = df_user_filadelfia.dropna()\n",
    "\n",
    "    return df_business_filadelfia,df_review_filadelfia,df_user_filadelfia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    words = text.split()\n",
    "    lemmatized_words = [lemmatizer.lemmatize(word) for word in words if word not in stop_words]\n",
    "    return ' '.join(lemmatized_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def stem_text(text):\n",
    "    words = text.split()\n",
    "    stemmed_words = [stemmer.stem(word) for word in words if word not in stop_words]\n",
    "    return ' '.join(stemmed_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pre-processamento\n",
    "def pre_processing(data_review,method):\n",
    "    if method == 'with lemma':\n",
    "\n",
    "        data_review['text'] = data_review['text'].apply(lemmatize_text)\n",
    "\n",
    "    \n",
    "    else: \n",
    "        data_review['text'] = data_review['text'].apply(stem_text)\n",
    "\n",
    "    return data_review\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature Engineering\n",
    "def feature_engineering(data_reviews, method):\n",
    "    if method == 'bag of words':\n",
    "        vectorizer = CountVectorizer(max_df=0.95, min_df=2)\n",
    "        matrix = vectorizer.fit_transform(data_reviews['text'])\n",
    "        matrix = matrix.toarray()\n",
    "        # feature_names = vectorizer.get_feature_names_out()\n",
    "        # df = pd.DataFrame(matrix, columns=feature_names)\n",
    "\n",
    "    # elif method=='word embeddings':\n",
    "    \n",
    "    elif method =='lda':\n",
    "        count_vectorizer = CountVectorizer(max_df=0.95, min_df=2)\n",
    "        count_matrix = count_vectorizer.fit_transform(data_reviews['text'])\n",
    "\n",
    "        lda_model = LatentDirichletAllocation(n_components=10, random_state=42)\n",
    "        matrix = lda_model.fit_transform(count_matrix)\n",
    "        # df = pd.DataFrame(matrix, columns=[f'Topic_{i}' for i in range(lda_model.n_components)])\n",
    "\n",
    "    return matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def features_business(df_business_filadelfia):\n",
    "    df_business_filadelfia = df_business_filadelfia[['business_id', 'name', 'stars', 'review_count','attributes', 'categories', 'hours']]\n",
    "\n",
    "\n",
    "    #variavel horario\n",
    "    df_business_filadelfia['hours'] = df_business_filadelfia['hours'].apply(lambda x: ast.literal_eval(x) if pd.notnull(x) else {})\n",
    "\n",
    "    # Crie colunas separadas para cada dia da semana\n",
    "    dias_da_semana = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "\n",
    "    for dia in dias_da_semana:\n",
    "        df_business_filadelfia[dia] = df_business_filadelfia['hours'].apply(lambda x: x.get(dia, None))\n",
    "\n",
    "    # Remova a coluna original 'hours' se não for mais necessária\n",
    "    df_business_filadelfia.drop(columns=['hours'], inplace=True)\n",
    "\n",
    "\n",
    "    def categorize_hours(hours):\n",
    "\n",
    "        if hours == None:\n",
    "            return 0 #'Fechado'\n",
    "        \n",
    "        else:\n",
    "            start_time, end_time = hours.split('-')\n",
    "            start_hour = int(start_time.split(':')[0])\n",
    "            end_hour = int(end_time.split(':')[0])\n",
    "            \n",
    "            if end_hour <= 12:\n",
    "                return 1 #'Manhã'\n",
    "            elif 12 < start_hour and end_hour<=15:\n",
    "                return 2 #'Almoço'\n",
    "            elif start_hour > 15 and end_hour < 19:\n",
    "                return 3 #'Tarde'\n",
    "            elif start_hour>=19:\n",
    "                return 4 #'Noite'\n",
    "            else:\n",
    "                return 5 #'Dia todo'\n",
    "\n",
    "    # Aplicar a função de categorização a cada coluna de dia da semana\n",
    "    for day in ['Monday', 'Tuesday', 'Wednesday','Thursday', 'Friday', 'Saturday', 'Sunday']:\n",
    "        df_business_filadelfia[day] = df_business_filadelfia[day].apply(categorize_hours)\n",
    "\n",
    "\n",
    "    #variavel categoria\n",
    "\n",
    "    df_business_filadelfia['Restaurants'] = 0\n",
    "    df_business_filadelfia['Food'] = 0\n",
    "    df_business_filadelfia['Nightlife'] = 0\n",
    "    df_business_filadelfia['Bars'] = 0\n",
    "    df_business_filadelfia['Sandwiches'] = 0\n",
    "    df_business_filadelfia['American (New)'] = 0\n",
    "    df_business_filadelfia['Pizza'] = 0\n",
    "    df_business_filadelfia['Breakfast & Brunch'] = 0\n",
    "    df_business_filadelfia['American (Traditional)'] = 0\n",
    "    df_business_filadelfia['Coffee & Tea'] = 0\n",
    "\n",
    "    for index, row in df_business_filadelfia.iterrows():\n",
    "        categories = row['categories']\n",
    "        if 'Restaurants' in categories:\n",
    "            df_business_filadelfia.at[index, 'Restaurantes'] = 1\n",
    "\n",
    "        if 'Food' in categories:\n",
    "            df_business_filadelfia.at[index, 'Food'] = 1\n",
    "\n",
    "        if 'Nightlife' in categories:\n",
    "            df_business_filadelfia.at[index, 'Nightlife'] = 1\n",
    "\n",
    "        if 'Bars' in categories:\n",
    "            df_business_filadelfia.at[index, 'Bars'] = 1\n",
    "\n",
    "        if 'Sandwiches' in categories:\n",
    "            df_business_filadelfia.at[index, 'Sandwiches'] = 1\n",
    "\n",
    "        if 'American (New)' in categories:\n",
    "            df_business_filadelfia.at[index, 'American (New)'] = 1\n",
    "        \n",
    "        if 'Pizza' in categories:\n",
    "            df_business_filadelfia.at[index, 'Pizza'] = 1\n",
    "\n",
    "        if 'Breakfast & Brunch' in categories:\n",
    "            df_business_filadelfia.at[index, 'Breakfast & Brunch'] = 1\n",
    "\n",
    "        if 'American (Traditional)' in categories:\n",
    "            df_business_filadelfia.at[index, 'American (Traditional)'] = 1\n",
    "\n",
    "        if 'Coffee & Tea' in categories:\n",
    "            df_business_filadelfia.at[index, 'Coffee & Tea'] = 1\n",
    "\n",
    "\n",
    "\n",
    "        #variavel atributos\n",
    "\n",
    "        df_business_filadelfia['RestaurantsDelivery'] = 0\n",
    "        df_business_filadelfia['OutdoorSeating'] = 0\n",
    "        df_business_filadelfia['BusinessAcceptsCreditCards'] = 0\n",
    "        df_business_filadelfia['BikeParking'] = 0\n",
    "        df_business_filadelfia['RestaurantsTakeOut'] = 0\n",
    "        df_business_filadelfia['ByAppointmentOnly'] = 0\n",
    "        df_business_filadelfia['Caters'] = 0\n",
    "        df_business_filadelfia['RestaurantsReservations'] = 0\n",
    "        df_business_filadelfia['RestaurantsGoodForGroups'] = 0\n",
    "        df_business_filadelfia['HasTV'] = 0\n",
    "        df_business_filadelfia['GoodForKids'] = 0\n",
    "        df_business_filadelfia['DogsAllowed'] = 0\n",
    "        df_business_filadelfia['HappyHour'] = 0\n",
    "        df_business_filadelfia['WheelchairAccessible'] = 0\n",
    "        df_business_filadelfia['RestaurantsTableService'] = 0\n",
    "        df_business_filadelfia['BusinessAcceptsBitcoin'] = 0\n",
    "        df_business_filadelfia['Corkage'] = 0\n",
    "        df_business_filadelfia['CoatCheck'] = 0\n",
    "        df_business_filadelfia['BYOB'] = 0\n",
    "        df_business_filadelfia['DriveThru'] = 0\n",
    "\n",
    "\n",
    "        for index, row in df_business_filadelfia.iterrows():\n",
    "            categories = row['categories']\n",
    "            if 'RestaurantsDelivery' in categories:\n",
    "                df_business_filadelfia.at[index, 'RestaurantsDelivery'] = 1\n",
    "\n",
    "            if 'OutdoorSeating' in categories:\n",
    "                df_business_filadelfia.at[index, 'OutdoorSeating'] = 1\n",
    "\n",
    "            if 'BusinessAcceptsCreditCards' in categories:\n",
    "                df_business_filadelfia.at[index, 'BusinessAcceptsCreditCards'] = 1\n",
    "\n",
    "            if 'BikeParking' in categories:\n",
    "                df_business_filadelfia.at[index, 'BikeParking'] = 1\n",
    "\n",
    "            if 'RestaurantsTakeOut' in categories:\n",
    "                df_business_filadelfia.at[index, 'RestaurantsTakeOut'] = 1\n",
    "\n",
    "            if 'ByAppointmentOnly' in categories:\n",
    "                df_business_filadelfia.at[index, 'ByAppointmentOnly'] = 1\n",
    "            \n",
    "            if 'Caters' in categories:\n",
    "                df_business_filadelfia.at[index, 'Caters'] = 1\n",
    "\n",
    "            if 'RestaurantsReservations' in categories:\n",
    "                df_business_filadelfia.at[index, 'RestaurantsReservations'] = 1\n",
    "\n",
    "            if 'RestaurantsGoodForGroups' in categories:\n",
    "                df_business_filadelfia.at[index, 'RestaurantsGoodForGroups'] = 1\n",
    "\n",
    "            if 'HasTV' in categories:\n",
    "                df_business_filadelfia.at[index, 'HasTV'] = 1\n",
    "\n",
    "            if 'GoodForKids' in categories:\n",
    "                df_business_filadelfia.at[index, 'GoodForKids'] = 1\n",
    "\n",
    "            if 'DogsAllowed' in categories:\n",
    "                df_business_filadelfia.at[index, 'DogsAllowed'] = 1\n",
    "\n",
    "            if 'HappyHour' in categories:\n",
    "                df_business_filadelfia.at[index, 'HappyHour'] = 1\n",
    "\n",
    "            if 'WheelchairAccessible' in categories:\n",
    "                df_business_filadelfia.at[index, 'WheelchairAccessible'] = 1\n",
    "\n",
    "            if 'RestaurantsTableService' in categories:\n",
    "                df_business_filadelfia.at[index, 'RestaurantsTableService'] = 1\n",
    "\n",
    "            if 'BusinessAcceptsBitcoin' in categories:\n",
    "                df_business_filadelfia.at[index, 'BusinessAcceptsBitcoin'] = 1\n",
    "\n",
    "            if 'Corkage' in categories:\n",
    "                df_business_filadelfia.at[index, 'Corkage'] = 1\n",
    "            \n",
    "            if 'CoatCheck' in categories:\n",
    "                df_business_filadelfia.at[index, 'CoatCheck'] = 1\n",
    "\n",
    "            if 'BYOB' in categories:\n",
    "                df_business_filadelfia.at[index, 'BYOB'] = 1\n",
    "\n",
    "            if 'DriveThru' in categories:\n",
    "                df_business_filadelfia.at[index, 'DriveThru'] = 1\n",
    "\n",
    "        df_business_filadelfia.columns = ['business_id', 'name', 'stars', 'review_count_business', 'attributes', 'categories', 'Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday',\n",
    "       'Saturday', 'Sunday', 'Restaurants', 'Food', 'Nightlife', 'Bars', 'Sandwiches', 'American (New)', 'Pizza', 'Breakfast & Brunch', 'American (Traditional)', 'Coffee & Tea', 'Restaurantes',\n",
    "       'RestaurantsDelivery', 'OutdoorSeating', 'BusinessAcceptsCreditCards', 'BikeParking', 'RestaurantsTakeOut', 'ByAppointmentOnly', 'Caters','RestaurantsReservations', 'RestaurantsGoodForGroups', 'HasTV',\n",
    "       'GoodForKids', 'DogsAllowed', 'HappyHour', 'WheelchairAccessible','RestaurantsTableService', 'BusinessAcceptsBitcoin', 'Corkage','CoatCheck', 'BYOB', 'DriveThru']\n",
    "        \n",
    "        df_business_filadelfia=df_business_filadelfia.drop(['attributes', 'categories','name'],axis=1)\n",
    "\n",
    "        return df_business_filadelfia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def features_user(df_user_filadelfia):\n",
    "\n",
    "\n",
    "    yelping_since = pd.to_datetime(df_user_filadelfia['yelping_since'])\n",
    "\n",
    "    # Calcule o número de anos no Yelp\n",
    "    current_year = datetime.now().year\n",
    "    df_user_filadelfia['yelping_since'] = current_year - yelping_since.dt.year\n",
    "\n",
    "\n",
    "    df_user_filadelfia.columns = ['user_id', 'name', 'review_count_user', 'yelping_years', 'elite', 'average_stars']\n",
    "    df_user_filadelfia=df_user_filadelfia.drop(['elite','name'],axis=1)\n",
    "    # df_user_filadelfia=df_user_filadelfia.drop('yelping_since',axis=1)\n",
    "\n",
    "        \n",
    "\n",
    "    return df_user_filadelfia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Divisão teste e treino\n",
    "#por enquanto está assim mas depois temos de definir como vamos querer dividir \n",
    "def split_data(final_data,business_data,users_data):\n",
    "\n",
    "    general_trainset, general_testset = train_test_split(final_data, test_size=0.20, random_state=42)\n",
    "\n",
    "    # Criar users_trainset e users_testset\n",
    "    users_trainset = users_data[users_data['user_id'].isin(general_trainset['user_id'])]\n",
    "    users_testset = users_data[users_data['user_id'].isin(general_testset['user_id'])]\n",
    "\n",
    "    # Criar business_trainset e business_testset\n",
    "    business_trainset = business_data[business_data['business_id'].isin(general_trainset['business_id'])]\n",
    "    business_testset = business_data[business_data['business_id'].isin(general_testset['business_id'])]\n",
    "\n",
    "    # Verificar os tamanhos dos conjuntos\n",
    "    print(\"Tamanho do trainset:\", len(general_trainset))\n",
    "    print(\"Tamanho do testset:\", len(general_testset))\n",
    "    print(\"Tamanho do users_trainset:\", len(users_trainset))\n",
    "    print(\"Tamanho do users_testset:\", len(users_testset))\n",
    "    print(\"Tamanho do business_trainset:\", len(business_trainset))\n",
    "    print(\"Tamanho do business_testset:\", len(business_testset))\n",
    "\n",
    "    return general_trainset, general_testset,users_trainset, users_testset,business_trainset, business_testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_similar_restaurants(restaurant_id, philly_restaurants, similarity_matrix, n=5):\n",
    "    # Obter o índice do restaurante\n",
    "    idx = philly_restaurants.index[philly_restaurants['business_id'] == restaurant_id].tolist()[0]\n",
    "    \n",
    "    # Obter similaridade do restaurante com todos os outros\n",
    "    similars_indices = similarity_matrix[idx].argsort()[::-1]  # Do mais similar para o menos similar\n",
    "    \n",
    "    # Excluir o próprio restaurante da recomendação\n",
    "    similars_indices = similars_indices[similars_indices != idx]\n",
    "    \n",
    "    # Selecionar os n mais similares\n",
    "    similars_restaurants = philly_restaurants.iloc[similars_indices[:n]]\n",
    "    \n",
    "    return similars_restaurants[['business_id', 'name', 'categories', 'stars']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para recomendar com base nos restaurantes que o usuário já avaliou bem\n",
    "def recommend_for_user(user_id, philly_restaurants, algo, similarity_matrix, n=5):\n",
    "    # Obter os restaurantes avaliados pelo usuário\n",
    "    user_reviews = ratings[ratings['user_id'] == user_id]\n",
    "    highly_rated = user_reviews[user_reviews['stars'] >= 4]['business_id']\n",
    "    \n",
    "    # Para cada restaurante que o usuário gostou, recomendar restaurantes similares\n",
    "    recommendations = pd.DataFrame()\n",
    "    # print('highly rated ',highly_rated)\n",
    "\n",
    "    for restaurant_id in highly_rated:\n",
    "        try:\n",
    "            # Obter o índice do restaurante\n",
    "            inner_id = algo.trainset.to_inner_iid(restaurant_id)\n",
    "            \n",
    "            # Obter os restaurantes mais similares usando o modelo treinado\n",
    "            neighbors = algo.get_neighbors(inner_id, k=n)\n",
    "            # print('neighbors ',neighbors)\n",
    "            # Converter os índices internos para IDs de restaurantes\n",
    "            similar_restaurant_ids_knn = [algo.trainset.to_raw_iid(inner_id) for inner_id in neighbors]\n",
    "            \n",
    "            # Obter os detalhes dos restaurantes similares usando o modelo treinado\n",
    "            similar_restaurants_knn = philly_restaurants[philly_restaurants['business_id'].isin(similar_restaurant_ids_knn)]\n",
    "            # print('similar_restaurants_knn ',similar_restaurants_knn)\n",
    "        except ValueError:\n",
    "            # Se o restaurante não estiver no conjunto de treino, retornar um DataFrame vazio\n",
    "            similar_restaurants_knn = pd.DataFrame()\n",
    "        \n",
    "        # Obter os detalhes dos restaurantes similares usando a matriz de similaridade\n",
    "        similar_restaurants_matrix = recommend_similar_restaurants(restaurant_id, philly_restaurants, similarity_matrix, n)\n",
    "        # print('similar_restaurants_matrix ',similar_restaurants_matrix)\n",
    "        # Combinar as recomendações de ambos os métodos\n",
    "        combined_recommendations = pd.concat([similar_restaurants_knn, similar_restaurants_matrix]).drop_duplicates(subset='business_id')\n",
    "        \n",
    "        recommendations = pd.concat([recommendations, combined_recommendations])\n",
    "        # print('recommendations ',recommendations)\n",
    "    # Remover duplicatas e ordenar por popularidade (opcional: você pode melhorar o critério de ordenação)\n",
    "    recommendations = recommendations.drop_duplicates(subset='name').sort_values(by='stars', ascending=False)\n",
    "    # print('recommendations ',recommendations)\n",
    "    return recommendations['name'].head(n)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_n_similar_users(user_id, n,similarity_matrix,user_trainset):\n",
    "    if user_id in similarity_matrix.index:\n",
    "        similar_users = similarity_matrix[user_id].sort_values(ascending=False).index[1:n+1]\n",
    "    else:\n",
    "        from sklearn.neighbors import NearestNeighbors\n",
    "        knn = NearestNeighbors(n_neighbors=n, metric='cosine')\n",
    "        knn.fit(user_trainset)\n",
    "        distances, indices = knn.kneighbors(user_trainset.loc[user_id].values.reshape(1, -1), n_neighbors=n+1)\n",
    "        similar_users = user_trainset.index[indices.flatten()][1:]\n",
    "    return similar_users\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recommended_restaurants(user_id, similar_users, n,user_trainset):\n",
    "    target_user_ratings = user_trainset.loc[user_id]\n",
    "    target_user_visited = target_user_ratings[target_user_ratings > 0].index\n",
    "\n",
    "    similar_users_ratings = user_trainset.loc[similar_users]\n",
    "    similar_users_ratings = similar_users_ratings.drop(columns=target_user_visited, errors='ignore')\n",
    "\n",
    "    top_rated_restaurants = similar_users_ratings.mean().sort_values(ascending=False).head(n)\n",
    "    return top_rated_restaurants\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Avaliação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "methods_pre_processing = ['with lemma','with stemma']\n",
    "# methods_feature_engineering = ['bag of words', 'word embeddings', 'lda']\n",
    "methods_feature_engineering = ['bag of words','lda']\n",
    "add_features_decision = ['yes','no']\n",
    "algorithms_cf = ['CF-UB','CF-IB'] #CF-IB(Colaborative Filtering Item Based),CF-UB(Colaborative Filtering User Based)\n",
    "algorithms_content = ['UBH','IBH','UIBH'] #UBH(User Based Hybrid), IBH(Item Based Hybrid), UIBH(User Item Based Hybrid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Main\n",
    "feature_engineering_method = []\n",
    "algoritmo=[]\n",
    "accuracy = []\n",
    "precision = []\n",
    "f1_score = []\n",
    "recall = []\n",
    "\n",
    "def main():\n",
    "    df_business_filadelfia,df_review_filadelfia,df_user_filadelfia = load_data()\n",
    "\n",
    "    df_business_filadelfia=df_business_filadelfia.sample(1000)\n",
    "    df_review_filadelfia=df_review_filadelfia.sample(1000)\n",
    "    df_user_filadelfia=df_user_filadelfia.sample(1000)\n",
    "\n",
    "    for a in algorithms_cf:\n",
    "        if a == 'CF-UB':\n",
    "            algo = KNNBasic(sim_options={'user_based': True})\n",
    "            algo.fit(user_trainset)\n",
    "            predictions = algo.test(user_testset)\n",
    "\n",
    "        else:\n",
    "\n",
    "            algo = KNNBasic(sim_options={'user_based': False})\n",
    "            algo.fit(business_trainset)\n",
    "            predictions = algo.test(business_testset)  \n",
    "\n",
    "\n",
    "    for a in methods_pre_processing:\n",
    "        df_review_filadelfia_pre_processado = pre_processing(df_review_filadelfia,a)\n",
    "\n",
    "        for b in methods_feature_engineering:\n",
    "            matrix = feature_engineering(df_review_filadelfia_pre_processado,b)\n",
    "\n",
    "            for c in algorithms_content:\n",
    "                df_review_filadelfia = df_review_filadelfia.reset_index(drop=True)\n",
    "\n",
    "                if c == 'UBH':\n",
    "                    matrix_per_user = df_review_filadelfia.groupby('user_id').apply(lambda x: np.mean(matrix[x.index], axis=0))\n",
    "                    features = features_user(df_user_filadelfia)\n",
    "\n",
    "                    matrix_df = pd.DataFrame(matrix_per_user.tolist(), index=matrix_per_user.index)\n",
    "\n",
    "                    # Adiciona a coluna 'user_id' ao DataFrame\n",
    "                    matrix_df.reset_index(inplace=True)\n",
    "\n",
    "                    # Junta as features à matriz\n",
    "                    result_df = matrix_df.merge(features, on='user_id')\n",
    "\n",
    "                    result_matrix = result_df.set_index('user_id').to_numpy()\n",
    "\n",
    "                    similarity_matrix = cosine_similarity(result_matrix)\n",
    "\n",
    "                if c == 'IBH':\n",
    "                    matrix_per_business = df_review_filadelfia.groupby('business_id').apply(lambda x: np.mean(matrix[x.index], axis=0))\n",
    "                    features = features_business(df_business_filadelfia)\n",
    "\n",
    "                    matrix_df = pd.DataFrame(matrix_per_business.tolist(), index=matrix_per_business.index)\n",
    "\n",
    "                    # Adiciona a coluna 'business_id' ao DataFrame\n",
    "                    matrix_df.reset_index(inplace=True)\n",
    "\n",
    "                    # Junta as features à matriz\n",
    "                    result_df = matrix_df.merge(features, on='business_id')\n",
    "\n",
    "                    result_matrix = result_df.set_index('business_id').to_numpy()\n",
    "\n",
    "                    #há restaurantes na matriz que não têm info nas features, mas agora já não consigo pensar\n",
    "\n",
    "                    similarity_matrix = cosine_similarity(result_matrix)\n",
    "\n",
    "\n",
    "                return similarity_matrix\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.99544841, 0.9956561 , 0.99550571, 0.99320691,\n",
       "        0.99512158, 0.97249916, 0.99370598, 0.99560994, 0.99512402,\n",
       "        0.99566465, 0.99468465, 0.99510445, 0.99554181, 0.96953973,\n",
       "        0.99503323, 0.9954954 ],\n",
       "       [0.99544841, 1.        , 0.99861204, 0.99838974, 0.99591978,\n",
       "        0.99783472, 0.97700643, 0.99572167, 0.99871058, 0.99854622,\n",
       "        0.99869774, 0.99812797, 0.99797965, 0.99823546, 0.97154531,\n",
       "        0.99753358, 0.99831295],\n",
       "       [0.9956561 , 0.99861204, 1.        , 0.99958286, 0.99581111,\n",
       "        0.99938824, 0.97197443, 0.99640836, 0.9996102 , 0.99791619,\n",
       "        0.99928982, 0.99789648, 0.9978941 , 0.99941018, 0.96858762,\n",
       "        0.99865675, 0.99908913],\n",
       "       [0.99550571, 0.99838974, 0.99958286, 1.        , 0.99542662,\n",
       "        0.99978773, 0.96997742, 0.99636747, 0.99980537, 0.99736553,\n",
       "        0.99929694, 0.99763979, 0.99757971, 0.99964525, 0.96656999,\n",
       "        0.99882205, 0.99913428],\n",
       "       [0.99320691, 0.99591978, 0.99581111, 0.99542662, 1.        ,\n",
       "        0.99487779, 0.97450271, 0.9933151 , 0.9958191 , 0.99562086,\n",
       "        0.99595091, 0.99541835, 0.99558296, 0.99546823, 0.97000559,\n",
       "        0.99466321, 0.99557276],\n",
       "       [0.99512158, 0.99783472, 0.99938824, 0.99978773, 0.99487779,\n",
       "        1.        , 0.96757255, 0.99618468, 0.99963128, 0.99657858,\n",
       "        0.99894003, 0.99684643, 0.99690875, 0.99955955, 0.96492698,\n",
       "        0.99881262, 0.99891396],\n",
       "       [0.97249916, 0.97700643, 0.97197443, 0.96997742, 0.97450271,\n",
       "        0.96757255, 1.        , 0.97048659, 0.97125869, 0.9801121 ,\n",
       "        0.97352418, 0.97782985, 0.97697623, 0.97078765, 0.96870977,\n",
       "        0.96917797, 0.97255484],\n",
       "       [0.99370598, 0.99572167, 0.99640836, 0.99636747, 0.9933151 ,\n",
       "        0.99618468, 0.97048659, 1.        , 0.99651403, 0.99497372,\n",
       "        0.99651817, 0.99579263, 0.99490862, 0.99630712, 0.97043658,\n",
       "        0.99605613, 0.99604521],\n",
       "       [0.99560994, 0.99871058, 0.9996102 , 0.99980537, 0.9958191 ,\n",
       "        0.99963128, 0.97125869, 0.99651403, 1.        , 0.99773461,\n",
       "        0.99936958, 0.9978711 , 0.99776211, 0.9996193 , 0.96754144,\n",
       "        0.99877105, 0.99913725],\n",
       "       [0.99512402, 0.99854622, 0.99791619, 0.99736553, 0.99562086,\n",
       "        0.99657858, 0.9801121 , 0.99497372, 0.99773461, 1.        ,\n",
       "        0.99814986, 0.99800316, 0.9980508 , 0.99722176, 0.97373705,\n",
       "        0.99653565, 0.9977037 ],\n",
       "       [0.99566465, 0.99869774, 0.99928982, 0.99929694, 0.99595091,\n",
       "        0.99894003, 0.97352418, 0.99651817, 0.99936958, 0.99814986,\n",
       "        1.        , 0.99815482, 0.9981109 , 0.99915692, 0.97010877,\n",
       "        0.99834874, 0.99891306],\n",
       "       [0.99468465, 0.99812797, 0.99789648, 0.99763979, 0.99541835,\n",
       "        0.99684643, 0.97782985, 0.99579263, 0.9978711 , 0.99800316,\n",
       "        0.99815482, 1.        , 0.99764864, 0.99741142, 0.97348142,\n",
       "        0.99652877, 0.99761752],\n",
       "       [0.99510445, 0.99797965, 0.9978941 , 0.99757971, 0.99558296,\n",
       "        0.99690875, 0.97697623, 0.99490862, 0.99776211, 0.9980508 ,\n",
       "        0.9981109 , 0.99764864, 1.        , 0.99733874, 0.97182755,\n",
       "        0.99680413, 0.99756767],\n",
       "       [0.99554181, 0.99823546, 0.99941018, 0.99964525, 0.99546823,\n",
       "        0.99955955, 0.97078765, 0.99630712, 0.9996193 , 0.99722176,\n",
       "        0.99915692, 0.99741142, 0.99733874, 1.        , 0.96682889,\n",
       "        0.99873711, 0.99893571],\n",
       "       [0.96953973, 0.97154531, 0.96858762, 0.96656999, 0.97000559,\n",
       "        0.96492698, 0.96870977, 0.97043658, 0.96754144, 0.97373705,\n",
       "        0.97010877, 0.97348142, 0.97182755, 0.96682889, 1.        ,\n",
       "        0.96729074, 0.96910866],\n",
       "       [0.99503323, 0.99753358, 0.99865675, 0.99882205, 0.99466321,\n",
       "        0.99881262, 0.96917797, 0.99605613, 0.99877105, 0.99653565,\n",
       "        0.99834874, 0.99652877, 0.99680413, 0.99873711, 0.96729074,\n",
       "        1.        , 0.99834434],\n",
       "       [0.9954954 , 0.99831295, 0.99908913, 0.99913428, 0.99557276,\n",
       "        0.99891396, 0.97255484, 0.99604521, 0.99913725, 0.9977037 ,\n",
       "        0.99891306, 0.99761752, 0.99756767, 0.99893571, 0.96910866,\n",
       "        0.99834434, 1.        ]])"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main antiga"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Main\n",
    "feature_engineering_method = []\n",
    "algoritmo=[]\n",
    "accuracy = []\n",
    "precision = []\n",
    "f1_score = []\n",
    "recall = []\n",
    "\n",
    "def main():\n",
    "    df_business_filadelfia,df_review_filadelfia,df_user_filadelfia = load_data()\n",
    "\n",
    "    df_business_filadelfia=df_business_filadelfia.sample(1000)\n",
    "    df_review_filadelfia=df_review_filadelfia.sample(1000)\n",
    "    df_user_filadelfia=df_user_filadelfia.sample(1000)\n",
    "\n",
    "    for a in methods_pre_processing:\n",
    "        df_review_filadelfia_pre_processado = pre_processing(df_review_filadelfia,a)\n",
    "        # print(df_business_filadelfia)\n",
    "        # print(df_review_filadelfia)\n",
    "        # print(df_user_filadelfia)\n",
    "\n",
    "        for b in methods_feature_engineering:\n",
    "            feature_engineering_method.append(b)\n",
    "            final_data = feature_engineering(df_review_filadelfia_pre_processado,b)\n",
    "            # print(final_data)\n",
    "            for c in add_features_decision:\n",
    "                # print(a,b,c)\n",
    "                if c == 'yes':\n",
    "                    # business_data,users_data = add_features(final_data,df_business_filadelfia,df_review_filadelfia,df_user_filadelfia) #adicionamos as repetivas features a cada matriz\n",
    "                    colunas = add_features(final_data,df_business_filadelfia,df_review_filadelfia,df_user_filadelfia) #adicionamos as repetivas features a cada matriz\n",
    "                    print(colunas)\n",
    "                # else:\n",
    "                #     business_data=final_data\n",
    "                #     users_data=final_data\n",
    "                \n",
    "                # general_trainset, general_testset,user_trainset, user_testset,business_trainset, business_testset = split_data(final_data,business_data,users_data)\n",
    "\n",
    "                # print('general_trainset')\n",
    "                # print(general_trainset)\n",
    "\n",
    "                # print('general_testset')\n",
    "                # print(general_testset)\n",
    "\n",
    "                # print('user_trainset')\n",
    "                # print(user_trainset)\n",
    "\n",
    "                # print('user_testset')\n",
    "                # print(user_testset)\n",
    "\n",
    "                # print('business_trainset')\n",
    "                # print(business_trainset)\n",
    "\n",
    "                # print('business_testset')\n",
    "                # print(business_testset)\n",
    "\n",
    "    #             for d in algorithms:\n",
    "    #                 algoritmo.append(d)\n",
    "\n",
    "    #                 if d == 'CF-UB':\n",
    "    #                     algo = KNNBasic(sim_options={'user_based': True})\n",
    "    #                     algo.fit(user_trainset)\n",
    "    #                     predictions = algo.test(user_testset)\n",
    "\n",
    "    #                 elif d == 'CF-IB':\n",
    "    #                     algo = KNNBasic(sim_options={'user_based': False})\n",
    "    #                     algo.fit(business_trainset)\n",
    "    #                     predictions = algo.test(business_testset)\n",
    "\n",
    "    #                 elif d == 'UBH':\n",
    "    #                     similarity_matrix = cosine_similarity(user_trainset)\n",
    "    #                     similarity_matrix = pd.DataFrame(similarity_matrix, index=user_trainset.index, columns=user_trainset.index)\n",
    "\n",
    "    #                     for user_id in user_testset['user_id']:\n",
    "    #                         similar_users = get_top_n_similar_users(user_id, n=5)\n",
    "    #                         recommended_restaurants = get_recommended_restaurants(user_id, similar_users, n_restaurants=5)\n",
    "    #                         best_restaurant = recommended_restaurants.idxmax()\n",
    "\n",
    "\n",
    "    #                 elif d == 'IBH':\n",
    "    #                     for business_id in business_testset['business_id']:\n",
    "    #                         similarity_matrix = cosine_similarity(business_trainset)\n",
    "    #                         similarity_matrix = pd.DataFrame(similarity_matrix, index=business_trainset.index, columns=business_trainset.index)\n",
    "\n",
    "    #                         recommendations = recommend_for_user(user_id, philly_restaurants, algo, similarity_matrix, n=5)\n",
    "\n",
    "\n",
    "    #                 elif d == 'UIBH':\n",
    "    #                     similarity_matrix = cosine_similarity(user_trainset,business_trainset)\n",
    "    #                     similarity_matrix = pd.DataFrame(similarity_matrix, index=user_trainset.index, columns=business_trainset.index)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
